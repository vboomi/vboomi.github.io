define({ entries : {
    "Adams2017": {
        "abstract": "Modern biology increasingly relies on fluorescence microscopy, which is driving demand for smaller, lighter, and cheaper microscopes. However, traditional microscope architectures suffer from a fundamental trade-off: As lenses become smaller, they must either collect less light or image a smaller field of view. To break this fundamental trade-off between device size and performance, we present a new concept for three-dimensional (3D) fluorescence imaging that replaces lenses with an optimized amplitude mask placed a few hundred micrometers above the sensor and an efficient algorithm that can convert a single frame of captured sensor data into high-resolution 3D images. The result is FlatScope: perhaps the world's tiniest and lightest microscope. FlatScope is a lensless microscope that is scarcely larger than an image sensor (roughly 0.2 g in weight and less than 1 mm thick) and yet able to produce micrometer-resolution, high\u2013frame rate, 3D fluorescence movies covering a total volume of several cubic millimeters. The ability of FlatScope to reconstruct full 3D images from a single frame of captured sensor data allows us to image 3D volumes roughly 40,000 times faster than a laser scanning confocal microscope while providing comparable resolution. We envision that this new flat fluorescence microscopy paradigm will lead to implantable endoscopes that minimize tissue damage, arrays of imagers that cover large areas, and bendable, flexible microscopes that conform to complex topographies.",
        "author": "Adams, Jesse K and Boominathan, Vivek and Avants, Benjamin W and Vercosa, Daniel G and Ye, Fan and Baraniuk, Richard G and Robinson, Jacob T and Veeraraghavan, Ashok",
        "file": ":Users/vivekboominathan/Dropbox/Research_local/Optica_Lensless_review/Papers/Rice/2017 FlatScope.pdf:pdf",
        "journal": "Science Advances",
        "keywords": "Application:Microscopy,Mask:Amplitude mask,Thickness:180um",
        "month": "dec",
        "number": "12",
        "title": "{Single-frame 3D fluorescence microscopy with ultraminiature lensless FlatScope}",
        "type": "article",
        "url": "http://advances.sciencemag.org/content/3/12/e1701548.abstract",
        "volume": "3",
        "year": "2017"
    },
    "Antipa2017": {
        "abstract": "We demonstrate a compact and easy-to-build computational camera for single-shot 3D imaging. Our lensless system consists solely of a diffuser placed in front of a standard image sensor. Every point within the volumetric field-of-view projects a unique pseudorandom pattern of caustics on the sensor. By using a physical approximation and simple calibration scheme, we solve the large-scale inverse problem in a computationally efficient way. The caustic patterns enable compressed sensing, which exploits sparsity in the sample to solve for more 3D voxels than pixels on the 2D sensor. Our 3D voxel grid is chosen to match the experimentally measured two-point optical resolution across the field-of-view, resulting in 100 million voxels being reconstructed from a single 1.3 megapixel image. However, the effective resolution varies significantly with scene content. Because this effect is common to a wide range of computational cameras, we provide new theory for analyzing resolution in such systems.",
        "archiveprefix": "arXiv",
        "arxivid": "1710.02134",
        "author": "Antipa, Nick and Kuo, Grace and Heckel, Reinhard and Mildenhall, Ben and Bostan, Emrah and Ng, Ren and Waller, Laura",
        "doi": "10.1364/OPTICA.5.000001",
        "eprint": "1710.02134",
        "file": ":Users/vivekboominathan/Dropbox/Research_local/Optica_Lensless_review/Papers/Laura/2018 DiffuserCam.pdf:pdf",
        "issn": "2334-2536",
        "journal": "Optica",
        "keywords": "Diffuser,Mask:Diffuser,Thickness:9mm",
        "mendeley-tags": "Diffuser",
        "month": "jan",
        "number": "1",
        "pages": "1",
        "title": "{DiffuserCam: lensless single-exposure 3D imaging}",
        "type": "article",
        "url": "https://www.osapublishing.org/abstract.cfm?URI",
        "volume": "5",
        "year": "2018"
    },
    "Antipa2019": {
        "abstract": "Because image sensor chips have a finite bandwidth with which to read out pixels, recording video typically requires a trade-off between frame rate and pixel count. Compressed sensing techniques can circumvent this trade-off by assuming that the image is compressible. Here, we propose using multiplexing optics to spatially compress the scene, enabling information about the whole scene to be sampled from a row of sensor pixels, which can be read off quickly via a rolling shutter CMOS sensor. Conveniently, such multiplexing can be achieved with a simple lensless, diffuser-based imaging system. Using sparse recovery methods, we are able to recover 140 video frames at over 4,500 frames per second, all from a single captured image with a rolling shutter sensor. Our proof-of-concept system uses easily-fabricated diffusers paired with an off-the-shelf sensor. The resulting prototype enables compressive encoding of high frame rate video into a single rolling shutter exposure, and exceeds the sampling-limited performance of an equivalent global shutter system for sufficiently sparse objects.",
        "author": "Antipa, Nick and Oare, Patrick and Bostan, Emrah and Ng, Ren and Waller, Laura",
        "booktitle": "2019 IEEE International Conference on Computational Photography, ICCP 2019",
        "doi": "10.1109/ICCPHOT.2019.8747341",
        "isbn": "9781728132631",
        "keywords": "Application:Compressive,Application:Video,Mask:Diffuser",
        "month": "may",
        "publisher": "Institute of Electrical and Electronics Engineers Inc.",
        "title": "{Video from Stills: Lensless Imaging with Rolling Shutter}",
        "type": "inproceedings",
        "year": "2019"
    },
    "Asif2017": {
        "abstract": "\u2014FlatCam is a thin form-factor lensless camera that consists of a coded mask placed on top of a bare, conventional sensor array. Unlike a traditional, lens-based camera, where an image of the scene is directly recorded on the sensor pixels, each pixel in FlatCam records a linear combination of light from multiple scene elements. A computational algorithm is then used to demultiplex the recorded measurements and reconstruct an image of the scene. FlatCam is an instance of a coded aperture imaging system; however, unlike the vast majority of related work, we place the coded mask extremely close to the image sensor that enables thin and flat form-factor imaging devices. We employ a separable mask to ensure that both calibration and image reconstruction are scalable in terms of memory requirements and computational complexity. We demonstrate the potential of the FlatCam design using two prototypes: one at visible wavelengths and one at infrared wavelengths.",
        "author": "Asif, M. Salman and Ayremlou, Ali and Sankaranarayanan, Aswin and Veeraraghavan, Ashok and Baraniuk, Richard G.",
        "doi": "10.1109/TCI.2016.2593662",
        "file": ":Users/vivekboominathan/Dropbox/Research_local/Optica_Lensless_review/Papers/Rice/2017 FlatCam.pdf:pdf",
        "issn": "2333-9403",
        "journal": "IEEE Transactions on Computational Imaging",
        "keywords": "Mask:Amplitude mask,Thickness:1.2mm",
        "month": "sep",
        "number": "3",
        "pages": "384--397",
        "title": "{FlatCam: Thin, Lensless Cameras Using Coded Aperture and Computation}",
        "type": "article",
        "url": "http://ieeexplore.ieee.org/document/7517296/",
        "volume": "3",
        "year": "2017"
    },
    "Bahmani2015": {
        "abstract": "We investigate the problem of reconstructing signals from a subsampled convolution of their modulated versions and a known filter. The problem is studied as applies to specific imaging systems relying on spatial phase modulation by randomly coded \"masks.\" The diversity induced by the random masks is deemed to improve the conditioning of the deconvolution problem while maintaining sampling efficiency. We analyze a linear model of the system, where the joint effect of the spatial modulation, blurring, and spatial subsampling is represented by a measurement matrix. We provide a bound on the conditioning of this measurement matrix in terms of the number of masks, the dimension of the image, and certain characteristics of the blurring kernel and subsampling operator. The derived bound shows that stable deconvolution is possible with high probability even if the total number of (scalar) measurements is within a logarithmic factor of the image size. Furthermore, beyond a critical number of masks determined by the extent of blurring and subsampling, every additional mask improves the conditioning of the measurement matrix. We also consider a more interesting scenario where the target image is sparse. We show that under mild conditions on the blurring kernel, with high probability the measurement matrix is a restricted isometry when the number of masks is within a logarithmic factor of the sparsity of the image. Therefore, the image can be reconstructed using many sparse recovery algorithms such as the basis pursuit. The bound on the required number of masks is linear in sparsity of the image but it is logarithmic in its dimension. The bound provides a quantitative view of the effect of the blurring and subsampling on the required number of masks, which is critical for designing efficient imaging systems.",
        "archiveprefix": "arXiv",
        "arxivid": "1412.7890",
        "author": "Bahmani, Sohail and Romberg, Justin",
        "doi": "10.1109/TCI.2015.2485941",
        "eprint": "1412.7890",
        "issn": "2333-9403",
        "journal": "IEEE Transactions on Computational Imaging",
        "keywords": "Mask:DMD,Sensor:single-pixel,Type:Non-lensless",
        "month": "dec",
        "number": "4",
        "pages": "236--246",
        "publisher": "Institute of Electrical and Electronics Engineers (IEEE)",
        "title": "{Compressive Deconvolution in Random Mask Imaging}",
        "type": "article",
        "url": "http://ieeexplore.ieee.org/document/7286775/",
        "volume": "1",
        "year": "2015"
    },
    "Berto2017": {
        "abstract": "We propose and implement a broadband, compact, and low-cost wavefront sensing scheme by simply placing a thin diffuser in the close vicinity of a camera. The local wavefront gradient is determined from the local translation of the speckle pattern. The translation vector map is computed thanks to a fast diffeomorphic image registration algorithm and integrated to reconstruct the wavefront profile. The simple translation of speckle grains under local wavefront tip/tilt is ensured by the so-called \"memory effect\" of the diffuser. Quantitative wavefront measurements are experimentally demonstrated both for the few first Zernike polynomials and for phase-imaging applications requiring high resolution. We finally provided a theoretical description of the resolution limit that is supported experimentally.",
        "archiveprefix": "arXiv",
        "arxivid": "1710.03797",
        "author": "Berto, Pascal and Rigneault, Herv{\\'{e}} and Guillon, Marc",
        "doi": "10.1364/OL.42.005117",
        "eprint": "1710.03797",
        "issn": "0146-9592",
        "journal": "Optics Letters",
        "keywords": "Application:Wavefront,Mask:Diffuser",
        "month": "dec",
        "number": "24",
        "pages": "5117",
        "publisher": "Optical Society of America",
        "title": "{Wavefront-sensing with a thin diffuser}",
        "type": "article",
        "url": "https://www.osapublishing.org/abstract.cfm?URI",
        "volume": "42",
        "year": "2017"
    },
    "Bishara2010": {
        "abstract": "We demonstrate lensfree holographic microscopy on a chip to achieve approximately 0.6 microm spatial resolution corresponding to a numerical aperture of approximately 0.5 over a large field-of-view of approximately 24 mm2. By using partially coherent illumination from a large aperture (approximately 50 microm), we acquire lower resolution lensfree in-line holograms of the objects with unit fringe magnification. For each lensfree hologram, the pixel size at the sensor chip limits the spatial resolution of the reconstructed image. To circumvent this limitation, we implement a sub-pixel shifting based super-resolution algorithm to effectively recover much higher resolution digital holograms of the objects, permitting sub-micron spatial resolution to be achieved across the entire sensor chip active area, which is also equivalent to the imaging field-of-view (24 mm2) due to unit magnification. We demonstrate the success of this pixel super-resolution approach by imaging patterned transparent substrates, blood smear samples, as well as Caenoharbditis Elegans.",
        "author": "Bishara, Waheb and Su, Ting-Wei and Coskun, Ahmet F. and Ozcan, Aydogan",
        "doi": "10.1364/oe.18.011181",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Bishara et al. - 2010 - Lensfree on-chip microscopy over a wide field-of-view using pixel super-resolution.pdf:pdf",
        "issn": "1094-4087",
        "journal": "Optics Express",
        "keywords": "Application:Microscopy,Mask:Holography",
        "month": "may",
        "number": "11",
        "pages": "11181",
        "pmid": "20588977",
        "publisher": "The Optical Society",
        "title": "{Lensfree on-chip microscopy over a wide field-of-view using pixel super-resolution}",
        "type": "article",
        "volume": "18",
        "year": "2010"
    },
    "Boominathan2016": {
        "author": "Boominathan, Vivek and Adams, Jesse K. and Asif, M. Salman and Avants, Benjamin W. and Robinson, Jacob T. and Baraniuk, Richard G. and Sankaranarayanan, Aswin C. and Veeraraghavan, Ashok",
        "doi": "10.1109/MSP.2016.2581921",
        "file": ":Users/vivekboominathan/Dropbox/Research_local/Optica_Lensless_review/Papers/Rice/2016 SigProcMagazine Lensless Imaging.pdf:pdf",
        "issn": "10535888",
        "journal": "IEEE Signal Processing Magazine",
        "keywords": "Source:Review",
        "month": "sep",
        "number": "5",
        "pages": "23--35",
        "title": "{Lensless Imaging: A computational renaissance}",
        "type": "article",
        "url": "http://ieeexplore.ieee.org/document/7559956/",
        "volume": "33",
        "year": "2016"
    },
    "Boominathan2020": {
        "abstract": "We demonstrate a versatile thin lensless camera with a designed phase-mask placed at sub-2 mm from an imaging CMOS sensor. Using wave optics and phase retrieval methods, we present a general-purpose framework to create phase-masks that achieve desired sharp point-spread-functions (PSFs) for desired camera thicknesses. From a single 2D encoded measurement, we show the reconstruction of high-resolution 2D images, computational refocusing, and 3D imaging. This ability is made possible by our proposed high-performance contour-based PSF. The heuristic contour-based PSF is designed using concepts in signal processing to achieve maximal information transfer to a bit-depth limited sensor. Due to the efficient coding, we can use fast linear methods for high-quality image reconstructions and switch to iterative nonlinear methods for higher fidelity reconstructions and 3D imaging.",
        "author": "Boominathan, Vivek and Adams, Jesse K. and Robinson, Jacob T. and Veeraraghavan, Ashok",
        "doi": "10.1109/TPAMI.2020.2987489",
        "file": ":Users/vivekboominathan/Dropbox/Research_local/Optica_Lensless_review/Papers/Rice/2020 PhlatCam.pdf:pdf",
        "issn": "19393539",
        "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "keywords": "Application:3D,Application:Microscopy,Application:Photography,Mask:Phase mask,Thickness:2mm",
        "number": "7",
        "pages": "1618--1629",
        "pmid": "32324539",
        "title": "{PhlatCam: Designed Phase-Mask Based Thin Lensless Camera}",
        "type": "article",
        "volume": "42",
        "year": "2020"
    },
    "Cai2020": {
        "abstract": "Microlens array-based light-field imaging has been one of the most commonly used and effective technologies to record high-dimensional optical signals for developing various potential high-performance applications in many fields. However, the use of a microlens array generally suffers from an intrinsic trade-off between the spatial and angular resolutions. In this paper, we concentrate on exploiting a diffuser to explore a novel modality for light-field imaging. We demonstrate that the diffuser can efficiently angularly couple incident light rays into a detected image without needing any lens. To characterize and analyse this phenomenon, we establish a diffuser-encoding light-field transmission model, in which four-dimensional light fields are mapped into two-dimensional images via a transmission matrix describing the light propagation through the diffuser. Correspondingly, a calibration strategy is designed to flexibly determine the transmission matrix, so that light rays can be computationally decoupled from a detected image with adjustable spatio-angular resolutions, which are unshackled from the resolution limitation of the sensor. The proof-of-concept approach indicates the possibility of using scattering media for lensless four-dimensional light-field recording and processing, not just for two- or three-dimensional imaging.",
        "author": "Cai, Zewei and Chen, Jiawei and Pedrini, Giancarlo and Osten, Wolfgang and Liu, Xiaoli and Peng, Xiang",
        "doi": "10.1038/s41377-020-00380-x",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Cai et al. - 2020 - Lensless light-field imaging through diffuser encoding.pdf:pdf",
        "issn": "2047-7538",
        "journal": "Light: Science & Applications",
        "keywords": "Application:Lightfield,Mask:Diffuser",
        "month": "dec",
        "number": "1",
        "pages": "143",
        "publisher": "Springer Nature",
        "title": "{Lensless light-field imaging through diffuser encoding}",
        "type": "article",
        "url": "www.nature.com/lsa http://www.nature.com/articles/s41377-020-00380-x",
        "volume": "9",
        "year": "2020"
    },
    "Caroli1987": {
        "abstract": "Coded aperture imaging in high energy astronomy represents an important technical advance in instrumentation over the full energy range from X- to $\\gamma$-rays and is playing a unique role in those spectral ranges where other techniques become ineffective or impracticable due to limitations connected to the physics of interactions of photons with matter. The theory underlying this method of indirect imaging is of strong relevance both in design optimization of new instruments and in the data analysis process. The coded aperture imaging method is herein reviewed with emphasis on topics of mainly practical interest along with a description of already developed and forthcoming implementations. {\\textcopyright} 1987 D. Reidel Publishing Company.",
        "author": "Caroli, E. and Stephen, J. B. and {Di Cocco G. and Natalucci, L. and Spizzichino, A.",
        "doi": "10.1007/BF00171998",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Caroli et al. - 1987 - Coded aperture imaging in X- and gamma-ray astronomy.pdf:pdf",
        "issn": "0038-6308",
        "journal": "Space Science Reviews",
        "keywords": "Aerospace Technology and Astronautics,Application:X-rays,Applications:Gamma-rays,Astrophysics and Astroparticles,Planetology,Space Exploration and Astronautics),Space Sciences (including Extraterrestrial Physics",
        "mendeley-tags": "Application:X-rays,Applications:Gamma-rays",
        "month": "sep",
        "number": "3-4",
        "pages": "349--403",
        "publisher": "Kluwer Academic Publishers",
        "title": "{Coded aperture imaging in X- and gamma-ray astronomy}",
        "type": "article",
        "url": "https://link.springer.com/article/10.1007/BF00171998 http://link.springer.com/10.1007/BF00171998",
        "volume": "45",
        "year": "1987"
    },
    "Chi2009": {
        "abstract": "For the optical spectrum region, we describe a novel phase-coded aperture imaging system that can be used in a computational imaging camera. The optical design includes a phase-only screen followed by a detector array. A specific diffraction pattern forms at the detector array when the wavefront from a point source object passes through the phase screen. Since diffraction effects cannot be ignored in the optical regime, an iterative phase retrieval method is used to calculate the phase coded screen. Correlation type processing can be applied for the image recovery. Computer simulation results are presented to illustrate the excellent imaging performance of this camera. {\\textcopyright} 2009 Elsevier B.V. All rights reserved.",
        "author": "Chi, Wanli and George, Nicholas",
        "doi": "10.1016/j.optcom.2009.02.031",
        "issn": "00304018",
        "journal": "Optics Communications",
        "keywords": "Mask:Phase mask",
        "number": "11",
        "pages": "2110--2117",
        "publisher": "Elsevier B.V.",
        "title": "{Phase-coded aperture for optical imaging}",
        "type": "article",
        "url": "http://dx.doi.org/10.1016/j.optcom.2009.02.031",
        "volume": "282",
        "year": "2009"
    },
    "Chi2011": {
        "abstract": "Experimental results are shown for an integrated computational imaging system with a phase-coded aperture. A spatial light modulator works as a phase screen that diffracts light from a point object into a uniformly redundant array (URA). Excellent imaging results are achieved after correlation processing. The system has the same depth of field as a diffraction-limited lens. Potential applications are discussed.",
        "author": "Chi, Wanli and George, Nicholas",
        "doi": "10.1364/OE.19.004294",
        "issn": "1094-4087",
        "journal": "Optics Express",
        "keywords": "Mask:Phase mask,Mask:SLM",
        "number": "5",
        "pages": "4294",
        "pmid": "21369259",
        "title": "{Optical imaging with phase-coded aperture}",
        "type": "article",
        "url": "https://www.osapublishing.org/oe/abstract.cfm?uri",
        "volume": "19",
        "year": "2011"
    },
    "Cui2008": {
        "abstract": "Low-cost and high-resolution on-chip microscopes are vital for reducing cost and improving efficiency for modern biomedicine and bioscience. Despite the needs, the conventional microscope design has proven difficult to miniaturize. Here, we report the implementation and application of two high-resolution (\u22480.9 $\\mu$m for the first and \u22480.8 $\\mu$m for the second), lensless, and fully on-chip microscopes based on the optofluidic microscopy (OFM) method. These systems abandon the conventional microscope design, which requires expensive lenses and large space to magnify images, and instead utilizes microfluidic flow to deliver specimens across array(s) of micrometer-size apertures defined on a metal-coated CMOS sensor to generate direct projection images. The first system utilizes a gravity-driven microfluidic flow for sample scanning and is suited for imaging elongate objects, such as Caenorhabditis elegans; and the second system employs an electrokinetic drive for flow control and is suited for imaging cells and other spherical/ellipsoidal objects. As a demonstration of the OFM for bioscience research, we show that the prototypes can be used to perform automated phenotype characterization of different Caenorhabditis elegans mutant strains, and to image spores and single cellular entities. The optofluidic microscope design, readily fabricable with existing semiconductor and microfluidic technologies, offers low-cost and highly compact imaging solutions. More functionalities, such as on-chip phase and fluorescence imaging, can also be readily adapted into OFM systems. We anticipate that the OFM can significantly address a range of biomedical and bioscience needs, and engender new microscope applications. {\\textcopyright} 2008 by The National Academy of Sciences of the USA.",
        "author": "Cui, Xiquan and Lee, Lap Man and Heng, Xin and Zhong, Weiwei and Sternberg, Paul W. and Psaltis, Demetri and Yang, Changhuei",
        "doi": "10.1073/pnas.0804612105",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Cui et al. - 2008 - Lensless high-resolution on-chip optofluidic microscopes for Caenorhabditis elegans and cell imaging.pdf:pdf",
        "issn": "00278424",
        "journal": "Proceedings of the National Academy of Sciences of the United States of America",
        "keywords": "Application:Microfluidics,Mask:Shadow,Microfluidic,Optofluidic microscopy,Phenotype characterization,Type,Type:Lensless",
        "mendeley-tags": "Application:Microfluidics,Mask:Shadow,Type:Lensless",
        "month": "aug",
        "number": "31",
        "pages": "10670--10675",
        "pmid": "18663227",
        "publisher": "National Academy of Sciences",
        "title": "{Lensless high-resolution on-chip optofluidic microscopes for Caenorhabditis elegans and cell imaging}",
        "type": "article",
        "url": "www.pnas.orgcgidoi10.1073pnas.0804612105",
        "volume": "105",
        "year": "2008"
    },
    "DeWeert2015": {
        "abstract": "In certain imaging applications, conventional lens technology is constrained by the lack of materials which can effectively focus the radiation within a reasonable weight and volume. One solution is to use coded apertures-opaque plates perforated with multiple pinhole-like openings. If the openings are arranged in an appropriate pattern, then the images can be decoded and a clear image computed. Recently, computational imaging and the search for a means of producing programmable software-defined optics have revived interest in coded apertures. The former state-of-the-art masks, modified uniformly redundant arrays (MURAs), are effective for compact objects against uniform backgrounds, but have substantial drawbacks for extended scenes: (1) MURAs present an inherently ill-posed inversion problem that is unmanageable for large images, and (2) they are susceptible to diffraction: a diffracted MURA is no longer a MURA. We present a new class of coded apertures, separable Doubly-Toeplitz masks, which are efficiently decodable even for very large images-orders of magnitude faster than MURAs, and which remain decodable when diffracted. We implemented the masks using programmable spatial-light-modulators. Imaging experiments confirmed the effectiveness of separable Doubly-Toeplitz masks-images collected in natural light of extended outdoor scenes are rendered clearly.",
        "author": "DeWeert, Michael J. and Farm, Brian P.",
        "doi": "10.1117/1.OE.54.2.023102",
        "issn": "0091-3286",
        "journal": "Optical Engineering",
        "keywords": "Mask:Amplitude mask,Mask:SLM,Thickness:6.5 cm",
        "number": "2",
        "pages": "023102",
        "title": "{Lensless coded-aperture imaging with separable Doubly-Toeplitz masks}",
        "type": "article",
        "url": "http://opticalengineering.spiedigitallibrary.org/article.aspx?doi",
        "volume": "54",
        "year": "2015"
    },
    "Dicke1968": {
        "abstract": "A pinhole camera for which the entrance area, covered with a very large number of randomly distributed pinholes, is 50 per cent open is shown to be a very effective way of forming images of a complex of X-ray stars. A simple statistical trick is used to reduce the multitudinous overlapping images to a single image. Less than forty detected photons are needed to form an image of a single star.",
        "author": "Dicke, R. H.",
        "doi": "10.1086/180230",
        "issn": "0004-637X",
        "journal": "The Astrophysical Journal",
        "keywords": "Application:X-rays,Applications:Gamma-rays",
        "month": "aug",
        "pages": "L101",
        "publisher": "American Astronomical Society",
        "title": "{Scatter-Hole Cameras for X-Rays and Gamma Rays}",
        "type": "article",
        "url": "http://adsabs.harvard.edu/doi/10.1086/180230",
        "volume": "153",
        "year": "1968"
    },
    "Donoho2006": {
        "abstract": "Suppose is x an unknown vector in Rm(a digital image or signal); we plan to measure n general linear functionals of x and then reconstruct. If x is known to be compressible by transform coding with a known transform, and we reconstruct via the nonlinear procedure defined here, the number of measurements n can be dramatically smaller than the size m Thus, certain natural classes of images with m pixels need only n",
        "author": "Donoho, D.L.",
        "doi": "10.1109/TIT.2006.871582",
        "issn": "0018-9448",
        "journal": "IEEE Transactions on Information Theory",
        "keywords": "Adaptive sampling,Almost-spherical sections of Banach spaces,Basis Pursuit,Eigenvalues of random matrices,Gel'fand n-widths,Information-based complexity,Integrated sensing and processing,Minimum \u21131-norm decomposition,Optimal recovery,Quotient-of-a-Subspace theorem,Sparse solution of linear equations",
        "month": "apr",
        "number": "4",
        "pages": "1289--1306",
        "title": "{Compressed sensing}",
        "type": "article",
        "url": "http://ieeexplore.ieee.org/document/1614066/",
        "volume": "52",
        "year": "2006"
    },
    "Duarte2008": {
        "author": "Duarte, Marco F. and Davenport, Mark A. and Takhar, Dharmpal and Laska, Jason N. and Sun, Ting and Kelly, Kevin F. and Baraniuk, Richard G.",
        "doi": "10.1109/MSP.2007.914730",
        "issn": "1053-5888",
        "journal": "IEEE Signal Processing Magazine",
        "keywords": "Mask:DMD,Sensor:single-pixel,Type:Non-lensless",
        "month": "mar",
        "number": "2",
        "pages": "83--91",
        "publisher": "Institute of Electrical and Electronics Engineers Inc.",
        "title": "{Single-pixel imaging via compressive sampling}",
        "type": "article",
        "url": "http://ieeexplore.ieee.org/document/4472247/",
        "volume": "25",
        "year": "2008"
    },
    "Fang2018": {
        "abstract": "We present a flow cytometer on a microfluidic chip that integrates an inline lens-free holographic microscope. High-speed cell analysis necessitates that cells flow through the microfluidic channel at a high velocity, but the image sensor of the in-line holographic microscope needs a long exposure time. Therefore, to solve this problem, this paper proposes an S-type micro-channel and a pulse injection method. To increase the speed and accuracy of the hologram reconstruction, we improve the iterative initial constraint method and propose a background removal method. The focus images and cell concentrations can be accurately calculated by the developed method. Using whole blood cells to test the cell counting precision, we find that the cell counting error of the proposed method is less than 2%. This result shows that the on-chip flow cytometer has high precision. Due to its low price and small size, this flow cytometer is suitable for environments far away from laboratories, such as underdeveloped areas and outdoors, and it is especially suitable for point-of-care testing (POCT).",
        "author": "Fang, Yuan and Yu, Ningmei and Jiang, Yuquan and Dang, Chaoliang",
        "doi": "10.3390/mi9050227",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Fang et al. - 2018 - High-Precision Lens-Less Flow Cytometer on a Chip.pdf:pdf",
        "issn": "2072-666X",
        "journal": "Micromachines",
        "keywords": "Application:Microfluidics,Application:Microscopy,Mask:Holography,Type:Lensless",
        "month": "may",
        "number": "5",
        "pages": "227",
        "publisher": "MDPI AG",
        "title": "{High-Precision Lens-Less Flow Cytometer on a Chip}",
        "type": "article",
        "url": "www.mdpi.com/journal/micromachines http://www.mdpi.com/2072-666X/9/5/227",
        "volume": "9",
        "year": "2018"
    },
    "Fennell2021": {
        "abstract": "Lensless biological imaging systems are an emerging alternative to conventional microscopic systems because they enable a wide field of view imaging. While most microscopic systems sacrifice the field of view for magnification, lensless systems have taken advantage of small imaging pixel size, projection, digital magnification, and post-processing to compensate for diffracted images. A new lens-based system is designed to have the exact same wide field of view as that of a basic lensless setup. A new compound lens system design is utilized to achieve an explicit aim to have the same fields of view as the lensless setup. Then the characteristics of these two optical imaging setups (lensless and lens-based setups) are compared at this level of complexity to see what the minimal systems principles are needed to achieve the biological imaging goals for simplified and less expensive future designs. For both imaging systems, images of biological entities are recorded with the help of the same CMOS imaging device and computer software. The main contribution of this work is an exhaustive comparison between the performance characteristics of both systems using optical standards and biological images.",
        "author": "Fennell, Robert D. and Sher, Mazhar and Asghar, Waseem",
        "doi": "10.1016/j.optlaseng.2020.106326",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Fennell, Sher, Asghar - 2021 - Design, development, and performance comparison of wide field lensless and lens-based optical systems for.pdf:pdf",
        "issn": "01438166",
        "journal": "Optics and Lasers in Engineering",
        "keywords": "Application:Point of Care",
        "month": "feb",
        "publisher": "Elsevier Ltd",
        "title": "{Design, development, and performance comparison of wide field lensless and lens-based optical systems for point-of-care biological applications}",
        "type": "article",
        "url": "https://pubmed.ncbi.nlm.nih.gov/32905530/",
        "volume": "137",
        "year": "2021"
    },
    "Fienup2006": {
        "abstract": "It is often possible to reduce the requirements on an imaging system by placing greater demands either on an illumination system or on post-detection processing of the data collected by the system. An extreme example of this is a system with no receiver optics whatsoever. By illuminating an object or scene with coherent light having a shaped illumination pattern, the receiver can be a simple detector array with no imaging optics, detecting the speckle intensity pattern reflected from the object; an image of the object can be reconstructed by a phase retrieval algorithm.",
        "author": "Fienup, James R.",
        "doi": "10.1364/opex.14.000498",
        "issn": "1094-4087",
        "journal": "Optics Express",
        "keywords": "Detector arrays,Imaging systems,Laser beams,Phase retrieval,Spatial frequency,Speckle patterns,Type,Type:Lensless",
        "month": "jan",
        "number": "2",
        "pages": "498",
        "publisher": "The Optical Society",
        "title": "{Lensless coherent imaging by phase retrieval with an illumination pattern constraint}",
        "type": "article",
        "url": "https://www.osapublishing.org/viewmedia.cfm?uri",
        "volume": "14",
        "year": "2006"
    },
    "Gill2013": {
        "abstract": "We introduce a new type of diffractive element based on odd-symmetry phase gratings. Spiral arrangements of these gratings over photosensors constitute a new class of unprecedentedly-small computational camera. {\\textcopyright} OSA 2013.",
        "author": "Gill, Patrick R. and Stork, David G.",
        "booktitle": "Optics InfoBase Conference Papers",
        "doi": "10.1364/cosi.2013.cw4c.3",
        "isbn": "9781557529756",
        "issn": "21622701",
        "keywords": "Mask:Phase gratings,Thickness:100um",
        "month": "jun",
        "pages": "CW4C.3",
        "publisher": "Optical Society of America (OSA)",
        "title": "{Lensless ultra-miniature imagers using odd-symmetry spiral phase gratings}",
        "type": "inproceedings",
        "url": "https://www.osapublishing.org/abstract.cfm?uri",
        "year": "2013"
    },
    "Gill2017": {
        "abstract": "Thermal Escher sensors are pixel-efficient lensless diffractive computational thermal imagers whose point-spread functions contain sharp transitions and effectively wrap around pixel array borders. These compact devices support high-resolution sensing and imaging.",
        "author": "Gill, Patrick R. and Tringali, James and Schneider, Alex and Kabir, Salman and Stork, David G. and Erickson, Evan and Kellam, Mark",
        "booktitle": "Optics InfoBase Conference Papers",
        "doi": "10.1364/COSI.2017.CTu3B.3",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Gill et al. - 2017 - Thermal Escher sensors Pixel-efficient lensless imagers based on tiled optics.pdf:pdf",
        "isbn": "9781557528209",
        "keywords": "Mask:Phase gratings,Sensor:Thermal",
        "month": "jun",
        "pages": "CTu3B.3",
        "publisher": "OSA - The Optical Society",
        "title": "{Thermal Escher sensors: Pixel-efficient lensless imagers based on tiled optics}",
        "type": "inproceedings",
        "url": "https://www.osapublishing.org/abstract.cfm?uri",
        "volume": "Part F46-C",
        "year": "2017"
    },
    "Goodman1966": {
        "author": "Goodman, J. W. and Huntley, W. H. and Jackson, D. W. and Lehmann, M.",
        "doi": "10.1063/1.1754453",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Goodman et al. - 1966 - Wavefront-reconstruction imaging through random media.pdf:pdf",
        "issn": "00036951",
        "journal": "Applied Physics Letters",
        "keywords": "Application:Wavefront,Mask:Diffuser,Type:Lensless",
        "month": "nov",
        "number": "12",
        "pages": "311--313",
        "publisher": "American Institute of PhysicsAIP",
        "title": "{Wavefront-reconstruction imaging through random media}",
        "type": "article",
        "url": "https://doi.org/10.1063/1.1754453",
        "volume": "8",
        "year": "1966"
    },
    "Goodman2004": {
        "abstract": "Fourier analysis is a ubiquitous tool that has found application to diverse areas of physics and engineering. This book deals with its applications in optics, and in particular with its applications to diffraction, imaging, optical data processing, holography and optical communications.",
        "author": "Goodman, Joseph W.",
        "isbn": "0974707724",
        "pages": "491",
        "publisher": "Roberts & Co",
        "title": "{Introduction to Fourier Optics, Third Edition}",
        "type": "book",
        "year": "2004"
    },
    "Goodman2015": {
        "author": "Goodman, Joseph W.",
        "edition": "2nd Editio",
        "isbn": "978-1-119-00948-1",
        "keywords": "Type:Non-lensless",
        "publisher": "John Wiley & Sons",
        "title": "{Statistical optics}",
        "type": "book",
        "year": "2015"
    },
    "Harm2014": {
        "abstract": "Objects imaged through thin scattering media can be reconstructed with the knowledge of the complex transmission function of the diffuser. We demonstrate image reconstruction of static and dynamic objects with numerical phase conjugation in a lensless setup. Data is acquired by single shot intensity capture of an object coherently illuminated and obscured by an inhomogeneous medium, i.e. light diffracted at a specimen is scattered by a polycarbonate diffuser and the resulting speckle field is recorded. As a preparational step, which has to be performed only one time before imaging, the complex speckle field diffracted by the diffuser to the camera chip is measured interferometrically, which allows to reconstruct the transmission function of the diffuser. After insertion of the specimen, the speckle field in the camera plane changes, and the complex field of the sample can be reconstructed from the new intensity distribution. After initial interferometric measurement of the diffuser field, the method is robust with respect to a subsequent misalignment of the diffuser. The method can be extended to image objects placed between a pair of thin scattering plates. Since the object information is contained in a single speckle intensity pattern, it is possible to image dynamic processes at video rate.",
        "author": "Harm, Walter and Roider, Clemens and Jesacher, Alexander and Bernet, Stefan and Ritsch-Marte, Monika",
        "doi": "10.1364/oe.22.022146",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Harm et al. - 2014 - Lensless imaging through thin diffusive media.pdf:pdf",
        "issn": "1094-4087",
        "journal": "Optics Express",
        "keywords": "(0901995) Digital holography,(0902880) Holographic interferometry,(1100113) Imaging through turbid media,OCIS codes: (1106150) Speckle imaging,Type:Lensless",
        "month": "sep",
        "number": "18",
        "pages": "22146",
        "publisher": "The Optical Society",
        "title": "{Lensless imaging through thin diffusive media}",
        "type": "article",
        "url": "https://www.osapublishing.org/viewmedia.cfm?uri",
        "volume": "22",
        "year": "2014"
    },
    "Heng2006": {
        "abstract": "We report a novel microfluidics-based lensless imaging technique, termed optofluidic microscopy (OFM), and demonstrate Caenorhabditis elegans imaging with an OFM prototype that gives comparable resolution to a conventional microscope and a measured resolution limit of 490 \u00b1 40 nm. {\\textcopyright} The Royal Society of Chemistry.",
        "author": "Heng, Xin and Erickson, David and Baugh, L. Ryan and Yaqoob, Zahid and Sternberg, Paul W. and Psaltis, Demetri and Yang, Changhuei",
        "doi": "10.1039/b604676b",
        "issn": "14730189",
        "journal": "Lab on a Chip",
        "keywords": "Application:Microfluidics,Mask:Shadow,Type:Lensless",
        "month": "sep",
        "number": "10",
        "pages": "1274--1276",
        "pmid": "17102839",
        "publisher": "Royal Society of Chemistry",
        "title": "{Optofluidic microscopy - A method for implementing a high resolution optical microscope on a chip}",
        "type": "article",
        "url": "www.rsc.org/loc",
        "volume": "6",
        "year": "2006"
    },
    "Horisaki2020": {
        "abstract": "In this Letter, we present a method for jointly designing a coded aperture and a convolutional neural network for reconstructing an object from a single-shot lensless measurement. The coded aperture and the reconstruction network are connected with a deep learning framework in which the coded aperture is placed as a first convolutional layer. Our co-optimization method was experimentally demonstrated with a fully convolutional network, and its performance was compared to a coded aperture with a modified uniformly redundant array.",
        "author": "Horisaki, Ryoichi and Okamoto, Yuka and Tanida, Jun",
        "doi": "10.1364/ol.390810",
        "issn": "0146-9592",
        "journal": "Optics Letters",
        "keywords": "Algorithm:DNN,Mask:Amplitude mask",
        "month": "jun",
        "number": "11",
        "pages": "3131",
        "pmid": "32479477",
        "publisher": "The Optical Society",
        "title": "{Deeply coded aperture for lensless imaging}",
        "type": "article",
        "url": "https://www.osapublishing.org/viewmedia.cfm?uri",
        "volume": "45",
        "year": "2020"
    },
    "Hua2020": {
        "abstract": "Lensless cameras, while extremely useful for imaging in constrained scenarios, struggle with resolving scenes with large depth variations. To resolve this, we propose imaging with a set of mask patterns displayed on a programmable mask, and introduce a computational focusing operator that helps to resolve the depth of scene points. As a result, the proposed imager can resolve dense scenes with large depth variations, allowing for more practical applications of lensless cameras. We also present a fast reconstruction algorithm for scene at multiple depths that reduces reconstruction time by two orders of magnitude. Finally, we build a prototype to show the proposed method improves both image quality and depth resolution of lensless cameras.",
        "author": "Hua, Yi and Nakamura, Shigeki and Asif, M. Salman and Sankaranarayanan, Aswin C.",
        "doi": "10.1109/TPAMI.2020.2986784",
        "issn": "19393539",
        "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "keywords": "Application:3D,Mask:Amplitude mask,Mask:Programmable",
        "month": "jul",
        "number": "7",
        "pages": "1606--1617",
        "pmid": "32305898",
        "publisher": "IEEE Computer Society",
        "title": "{SweepCam - Depth-Aware Lensless Imaging Using Programmable Masks}",
        "type": "article",
        "url": "https://pubmed.ncbi.nlm.nih.gov/32305898/",
        "volume": "42",
        "year": "2020"
    },
    "Huang2013": {
        "abstract": "In this paper, we propose a lensless compressive imaging architecture. The architecture consists of two components, an aperture assembly and a sensor. No lens is used. The aperture assembly consists of a two dimensional array of aperture elements. The transmittance of each aperture element is independently controllable. The sensor is a single detection element. A compressive sensing matrix is implemented by adjusting the transmittance of the individual aperture elements according to the values of the sensing matrix. The proposed architecture is simple and reliable because no lens is used. The architecture can be used for capturing images of visible and other spectra such as infrared, or millimeter waves, in surveillance applications for detecting anomalies or extracting features such as speed of moving objects. Multiple sensors may be used with a single aperture assembly to capture multiview images simultaneously. A prototype was built by using a LCD panel and a photoelectric sensor for capturing images of visible spectrum. {\\textcopyright} 2013 IEEE.",
        "author": "Huang, Gang and Jiang, Hong and Matthews, Kim and Wilford, Paul",
        "booktitle": "2013 IEEE International Conference on Image Processing, ICIP 2013 - Proceedings",
        "doi": "10.1109/ICIP.2013.6738433",
        "isbn": "9781479923410",
        "keywords": "Algorithm:Compressive,Mask:Amplitude mask,Mask:LCD,Mask:Programmable",
        "pages": "2101--2105",
        "title": "{Lensless imaging by compressive sensing}",
        "type": "inproceedings",
        "year": "2013"
    },
    "Isozaki2020": {
        "abstract": "Artificial intelligence (AI) has dramatically changed the landscape of science, industry, defence, and medicine in the last several years. Supported by considerably enhanced computational power and cloud storage, the field of AI has shifted from mostly theoretical studies in the discipline of computer science to diverse real-life applications such as drug design, material discovery, speech recognition, self-driving cars, advertising, finance, medical imaging, and astronomical observation, where AI-produced outcomes have been proven to be comparable or even superior to the performance of human experts. In these applications, what is essentially important for the development of AI is the data needed for machine learning. Despite its prominent importance, the very first process of the AI development, namely data collection and data preparation, is typically the most laborious task and is often a limiting factor of constructing functional AI algorithms. Lab-on-a-chip technology, in particular microfluidics, is a powerful platform for both the construction and implementation of AI in a large-scale, cost-effective, high-throughput, automated, and multiplexed manner, thereby overcoming the above bottleneck. On this platform, high-throughput imaging is a critical tool as it can generate high-content information (e.g., size, shape, structure, composition, interaction) of objects on a large scale. High-throughput imaging can also be paired with sorting and DNA/RNA sequencing to conduct a massive survey of phenotype-genotype relations whose data is too complex to analyze with traditional computational tools, but is analyzable with the power of AI. In addition to its function as a data provider, lab-on-a-chip technology can also be employed to implement the developed AI for accurate identification, characterization, classification, and prediction of objects in mixed, heterogeneous, or unknown samples. In this review article, motivated by the excellent synergy between AI and lab-on-a-chip technology, we outline fundamental elements, recent advances, future challenges, and emerging opportunities of AI with lab-on-a-chip technology or \"AI on a chip\"for short. This journal is",
        "author": "Isozaki, Akihiro and Harmon, Jeffrey and Zhou, Yuqi and Li, Shuai and Nakagawa, Yuta and Hayashi, Mika and Mikami, Hideharu and Lei, Cheng and Goda, Keisuke",
        "booktitle": "Lab on a Chip",
        "doi": "10.1039/d0lc00521e",
        "issn": "14730189",
        "month": "sep",
        "number": "17",
        "pages": "3074--3090",
        "pmid": "32644061",
        "publisher": "Royal Society of Chemistry",
        "title": "{AI on a chip}",
        "type": "misc",
        "url": "https://pubs.rsc.org/en/content/articlehtml/2020/lc/d0lc00521e https://pubs.rsc.org/en/content/articlelanding/2020/lc/d0lc00521e",
        "volume": "20",
        "year": "2020"
    },
    "Jiang2014": {
        "abstract": "Multi-view images are acquired by a lensless compressive imaging architecture, which consists of an aperture assembly and multiple sensors. The aperture assembly consists of a two-dimensional array of aperture elements whose transmittance can be individually controlled to implement a compressive sensing matrix. For each transmittance pattern of the aperture assembly, each of the sensors takes a measurement. The measurement vectors from the multiple sensors represent multi-view images of the same scene. We present theoretical framework for multi-view reconstruction and experimental results for enhancing quality of image using compressive measurements from multiple sensors.",
        "author": "Jiang, Hong and Huang, Gang and Wilford, Paul",
        "booktitle": "APSIPA Transactions on Signal and Information Processing",
        "doi": "10.1017/ATSIP.2014.16",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Jiang, Huang, Wilford - 2014 - Multi-view in lensless compressive imaging.pdf:pdf",
        "issn": "20487703",
        "keywords": "Image reconstruction,Lensless compressive imaging,Multi-view imaging,Type:Lensless",
        "month": "dec",
        "publisher": "Cambridge University Press",
        "title": "{Multi-view in lensless compressive imaging}",
        "type": "misc",
        "url": "https://doi.org/10.1017/ATSIP.2014.16",
        "volume": "3",
        "year": "2014"
    },
    "Jiang2020": {
        "abstract": "We report a novel lensless on-chip microscopy platform based on near-field blind ptychographic modulation. In this platform, we place a thin diffuser in between the object and the image sensor for light wave modulation. By blindly scanning the unknown diffuser to different x-y positions, we acquire a sequence of modulated intensity images for quantitative object recovery. Different from previous ptychographic implementations, we employ a unit magnification configuration with a Fresnel number of \u223c50 000, which is orders of magnitude higher than those of previous ptychographic setups. The unit magnification configuration allows us to have the entire sensor area, 6.4 mm by 4.6 mm, as the imaging field of view. The ultra-high Fresnel number enables us to directly recover the positional shift of the diffuser in the phase retrieval process, addressing the positioning accuracy issue plaguing regular ptychographic experiments. In our implementation, we use a low-cost, DIY scanning stage to perform blind diffuser modulation. Precise mechanical scanning that is critical in conventional ptychography experiments is no longer needed in our setup. We further employ an up-sampling phase retrieval scheme to bypass the resolution limit set by the imager pixel size and demonstrate a half-pitch resolution of 0.78 $\\mu$m. We validate the imaging performance via in vitro cell cultures, transparent and stained tissue sections, and a thick biological sample. We show that the recovered quantitative phase map can be used to perform effective cell segmentation of a dense yeast culture. We also demonstrate 3D digital refocusing of the thick biological sample based on the recovered wavefront. The reported platform provides a cost-effective and turnkey solution for large field-of-view, high-resolution, and quantitative on-chip microscopy. It is adaptable for a wide range of point-of-care-, global-health-, and telemedicine-related applications.",
        "author": "Jiang, Shaowei and Zhu, Jiakai and Song, Pengming and Guo, Chengfei and Bian, Zichao and Wang, Ruihai and Huang, Yikun and Wang, Shiyao and Zhang, He and Zheng, Guoan",
        "doi": "10.1039/c9lc01027k",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Jiang et al. - 2020 - Wide-field, high-resolution lensless on-chip microscopy via near-field blind ptychographic modulation.pdf:pdf",
        "issn": "14730189",
        "journal": "Lab on a Chip",
        "keywords": "Application:Microscopy",
        "month": "mar",
        "number": "6",
        "pages": "1058--1065",
        "pmid": "32073018",
        "publisher": "Royal Society of Chemistry",
        "title": "{Wide-field, high-resolution lensless on-chip microscopy: via near-field blind ptychographic modulation}",
        "type": "article",
        "url": "https://pubs.rsc.org/en/content/articlehtml/2020/lc/c9lc01027k https://pubs.rsc.org/en/content/articlelanding/2020/lc/c9lc01027k",
        "volume": "20",
        "year": "2020"
    },
    "Khan2019": {
        "abstract": "Recent advancements in fields like Internet of Things (IoT), augmented reality, etc. have led to an unprecedented demand for miniature cameras with low cost that can be integrated anywhere and can be used for distributed monitoring. Mask-based lensless imaging systems make such inexpensive and compact models realizable. However, reduction in the size and cost of these imagers comes at the expense of their image quality due to the high degree of multiplexing inherent in their design. In this paper, we present a method to obtain image reconstructions from mask-based lensless measurements that are more photorealistic than those currently available in the literature. We particularly focus on FlatCam, a lensless imager consisting of a coded mask placed over a bare CMOS sensor. Existing techniques for reconstructing FlatCam measurements suffer from several drawbacks including lower resolution and dynamic range than lens-based cameras. Our approach overcomes these drawbacks using a fully trainable non-iterative deep learning based model. Our approach is based on two stages: An inversion stage that maps the measurement into the space of intermediate reconstruction and a perceptual enhancement stage that improves this intermediate reconstruction based on perceptual and signal distortion metrics. Our proposed method is fast and produces photo-realistic reconstruction as demonstrated on many real and challenging scenes.",
        "author": "Khan, Salman Siddique and Adarsh, R. V. and Boominathan, Vivek and Tan, Jasper and Veeraraghavan, Ashok and Mitra, Kaushik",
        "doi": "10.1109/ICCV.2019.00795",
        "file": ":Users/vivekboominathan/Dropbox/Research_local/Optica_Lensless_review/Papers/Rice/2019 ICCV Towards_Photorealistic_Reconstruction_of_Highly_Multiplexed_Lensless_Images.pdf:pdf",
        "isbn": "9781728148038",
        "issn": "15505499",
        "journal": "Proceedings of the IEEE International Conference on Computer Vision",
        "keywords": "Algorithm:DNN,Mask:Amplitude mask",
        "pages": "7859--7868",
        "title": "{Towards photorealistic reconstruction of highly multiplexed lensless images}",
        "type": "article",
        "volume": "2019-Octob",
        "year": "2019"
    },
    "Khan2020": {
        "abstract": "Lensless imaging has emerged as a potential solution towards realizing ultra-miniature cameras by eschewing the bulky lens in a traditional camera. Without a focusing lens, the lensless cameras rely on computational algorithms to recover the scenes from multiplexed measurements. However, the current iterative-optimization-based reconstruction algorithms produce noisier and perceptually poorer images. In this work, we propose a non-iterative deep learning-based reconstruction approach that results in orders of magnitude improvement in image quality for lensless reconstructions. Our approach, called FlatNet, lays down a framework for reconstructing high-quality photorealistic images from mask-based lensless cameras, where the camera's forward model formulation is known. FlatNet consists of two stages: (1) an inversion stage that maps the measurement into a space of intermediate reconstruction by learning parameters within the forward model formulation, and (2) a perceptual enhancement stage that improves the perceptual quality of this intermediate reconstruction. These stages are trained together in an end-to-end manner. We show high-quality reconstructions by performing extensive experiments on real and challenging scenes using two different types of lensless prototypes: one which uses a separable forward model and another, which uses a more general non-separable cropped-convolution model. Our end-to-end approach is fast, produces photorealistic reconstructions, and is easy to adopt for other mask-based lensless cameras.",
        "archiveprefix": "arXiv",
        "arxivid": "2010.15440",
        "author": "Khan, Salman Siddique and Sundar, Varun and Boominathan, Vivek and Veeraraghavan, Ashok and Mitra, Kaushik",
        "doi": "10.1109/TPAMI.2020.3033882",
        "eprint": "2010.15440",
        "file": ":Users/vivekboominathan/Dropbox/Research_local/Optica_Lensless_review/Papers/Rice/2020 FlatNet.pdf:pdf",
        "issn": "19393539",
        "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "keywords": "Algorithm:DNN,Mask:Amplitude mask,Mask:Phase mask",
        "title": "{FlatNet: Towards Photorealistic Scene Reconstruction from Lensless Measurements}",
        "type": "article",
        "year": "2020"
    },
    "Kim2017": {
        "abstract": "Photography usually requires optics in conjunction with a recording device (an image sensor). Eliminating the optics could lead to new form factors for cameras. Here, we report a simple demonstration of imaging using a bare CMOS sensor that utilizes computation. The technique relies on the space variant point-spread functions resulting from the interaction of a point source in the field of view with the image sensor. These space-variant point-spread functions are combined with a reconstruction algorithm in order to image simple objects displayed on a discrete LED array as well as on an LCD screen. We extended the approach to video imaging. Finally, we performed experiments to analyze the parametric impact of the object distance. Improving the sensor designs and reconstruction algorithms can lead to useful cameras without optics.",
        "archiveprefix": "arXiv",
        "arxivid": "1702.06619",
        "author": "Kim, Ganghun and Isaacson, Kyle and Palmer, Rachael and Menon, Rajesh",
        "doi": "10.1364/AO.56.006450",
        "eprint": "1702.06619",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Kim et al. - 2017 - Lensless photography with only an image sensor.pdf:pdf",
        "issn": "15394522",
        "journal": "Applied optics",
        "keywords": "Mask:Bare Sensor",
        "month": "aug",
        "number": "23",
        "pages": "6450--6456",
        "pmid": "29047934",
        "publisher": "Optical Society of America",
        "title": "{Lensless photography with only an image sensor}",
        "type": "article",
        "url": "https://www.osapublishing.org/abstract.cfm?URI",
        "volume": "56",
        "year": "2017"
    },
    "Kuo2017": {
        "abstract": "We propose a lensless, diffuser-based camera with a simple calibration scheme. We investigate the resolution, field of view, and depth of field of our system, and we show results from two prototypes.",
        "address": "Washington, D.C.",
        "author": "Kuo, Grace and Antipa, Nick and Ng, Ren and Waller, Laura",
        "booktitle": "Imaging and Applied Optics 2017 (3D, AIO, COSI, IS, MATH, pcAOP)",
        "doi": "10.1364/COSI.2017.CTu3B.2",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Kuo et al. - 2017 - DiffuserCam Diffuser-Based Lensless Cameras.pdf:pdf",
        "isbn": "978-1-943580-29-3",
        "keywords": "Mask:Diffuser,Thickness:6.4mm,Thickness:8.8mm,Type:Lensless",
        "month": "jun",
        "pages": "CTu3B.2",
        "publisher": "OSA",
        "title": "{DiffuserCam: Diffuser-Based Lensless Cameras}",
        "type": "inproceedings",
        "url": "https://www.osapublishing.org/abstract.cfm?uri",
        "volume": "Part F46-C",
        "year": "2017"
    },
    "Kuo2020": {
        "abstract": "We present an on-chip, widefield fluorescence microscope, which consists of a diffuser placed a few millimeters away from a traditional image sensor. The diffuser replaces the optics of a microscope, resulting in a compact and easy-to-assemble system with a practical working distance of over 1.5 mm. Furthermore, the diffuser encodes volumetric information, enabling refocusability in post-processing and three-dimensional (3D) imaging of sparse samples from a single acquisition. Reconstruction of images from the raw data requires a precise model of the system, so we introduce a practical calibration scheme and a physics-based forward model to efficiently account for the spatially-varying point spread function (PSF). To improve performance in low-light, we propose a random microlens diffuser, which consists of many small lenslets randomly placed on the mask surface and yields PSFs that are robust to noise. We build an experimental prototype and demonstrate our system on both planar and 3D samples.",
        "author": "Kuo, Grace and {Linda Liu Fanglin and Grossrubatscher, Irene and Ng, Ren and Waller, Laura",
        "doi": "10.1364/OE.382055",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Kuo et al. - 2020 - On-chip fluorescence microscopy with a random microlens diffuser.pdf:pdf",
        "issn": "1094-4087",
        "journal": "Optics Express",
        "keywords": "Algorithm:LocalConv,Application:Microscopy,Mask:Diffuser,Type:Lensless",
        "month": "mar",
        "number": "6",
        "pages": "8384",
        "pmid": "32225465",
        "publisher": "The Optical Society",
        "title": "{On-chip fluorescence microscopy with a random microlens diffuser}",
        "type": "article",
        "url": "https://www.osapublishing.org/viewmedia.cfm?uri",
        "volume": "28",
        "year": "2020"
    },
    "Lange2005": {
        "abstract": "This article reports on a miniaturized shadow imaging device for the investigation of the behavioral effects of spaceflight on the nematode Caenorhabditis elegans, a widely used model organism for the experimental study of genetics, development, radiobiology, as well as behavior and aging. Severe volume and power constraints for the design of satellite payloads indicate the need to miniaturize of space biology experiments and measurement systems. To address this issue, an integrated shadow imager has been developed. It consists of a polycarbonate microculture chamber with a volume of 4 $\\mu$L that supports cultures of C. elegans worms in liquid media. Gas exchange is enabled through a gas-permeable membrane forming the top of the chamber. Shadow images are acquired with a CMOS video camera chip attached to the bottom of the microchamber. Image artifacts due to diffraction at the worm bodies are reduced by decreasing illumination wavelength and object/camera distance. As an alternative to video acquisition, the filtered video output signal is used to determine worm activity, yielding a system that allows image acquisition in combination with a low-bandwidth activity measurement. Using the described system, the activity of C. elegans as a function of ambient temperature was measured. The nematodes were found to show an increase in stroke frequency with temperature. Data obtained by manual counting of worm strokes and the video signal showed good correlation. To our knowledge, this is the first demonstration of maintaining and monitoring C. elegans in a microfluidic environment. {\\textcopyright} 2004 Elsevier B.V. All rights reserved.",
        "author": "Lange, Dirk and Storment, Christopher W. and Conley, Catharine A. and Kovacs, Gregory T.A.",
        "doi": "10.1016/j.snb.2004.12.039",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Lange et al. - 2005 - A microfluidic shadow imaging system for the study of the nematode Caenorhabditis elegans in space.pdf:pdf",
        "issn": "09254005",
        "journal": "Sensors and Actuators B: Chemical",
        "keywords": "Application:Microfluidics,Mask:Shadow,Type:Lensless",
        "month": "jun",
        "number": "2",
        "pages": "904--914",
        "publisher": "Elsevier",
        "title": "{A microfluidic shadow imaging system for the study of the nematode Caenorhabditis elegans in space}",
        "type": "article",
        "url": "https://linkinghub.elsevier.com/retrieve/pii/S0925400504009037",
        "volume": "107",
        "year": "2005"
    },
    "Lee2011": {
        "abstract": "Miniaturization of imaging systems can significantly benefit clinical diagnosis in challenging environments, where access to physicians and good equipment can be limited. Sub-pixel resolving optofluidic microscope (SROFM) offers high-resolution imaging in the form of an on-chip device, with the combination of microfluidics and inexpensive CMOS image sensors. In this work, we report on the implementation of color SROFM prototypes with a demonstrated optical resolution of 0.66 $\\mu$m at their highest acuity. We applied the prototypes to perform color imaging of red blood cells (RBCs) infected with Plasmodium falciparum, a particularly harmful type of malaria parasites and one of the major causes of death in the developing world. {\\textcopyright} 2011 Lee et al.",
        "author": "Lee, Seung Ah and Leitao, Ricardo and Zheng, Guoan and Yang, Samuel and Rodriguez, Ana and Yang, Changhuei",
        "doi": "10.1371/journal.pone.0026127",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Lee et al. - 2011 - Color capable sub-pixel resolving optofluidic microscope and its application to blood cell imaging for malaria diagn.pdf:pdf",
        "issn": "19326203",
        "journal": "PLoS ONE",
        "keywords": "Application:Microfluidics,Mask:Shadow,Type:Lensless",
        "month": "oct",
        "number": "10",
        "pages": "26127",
        "pmid": "22022535",
        "publisher": "Public Library of Science",
        "title": "{Color capable sub-pixel resolving optofluidic microscope and its application to blood cell imaging for malaria diagnosis}",
        "type": "article",
        "url": "/pmc/articles/PMC3191177/ /pmc/articles/PMC3191177/?report",
        "volume": "6",
        "year": "2011"
    },
    "Lee2014": {
        "abstract": "Portable chip-scale microscopy devices can potentially address various imaging needs in mobile healthcare and environmental monitoring. Here, we demonstrate the adaptation of a smartphone's camera to function as a compact lensless microscope. Unlike other chip-scale microscopy schemes, this method uses ambient illumination as its light source and does not require the incorporation of a dedicated light source. The method is based on the shadow imaging technique where the sample is placed on the surface of the image sensor, which captures direct shadow images under illumination. To improve the image resolution beyond the pixel size, we perform pixel super-resolution reconstruction with multiple images at different angles of illumination, which are captured while the user is manually tilting the device around any ambient light source, such as the sun or a lamp. The lensless imaging scheme allows for sub-micron resolution imaging over an ultra-wide field-of-view (FOV). Image acquisition and reconstruction are performed on the device using a custom-built Android application, constructing a stand-alone imaging device for field applications. We discuss the construction of the device using a commercial smartphone and demonstrate the imaging capabilities of our system. {\\textcopyright} 2014 the Partner Organisations.",
        "author": "Lee, Seung Ah and Yang, Changhuei",
        "doi": "10.1039/c4lc00523f",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Lee, Yang - 2014 - A smartphone-based chip-scale microscope using ambient illumination.pdf:pdf",
        "issn": "14730189",
        "journal": "Lab on a Chip",
        "keywords": "Mask:Shadow,Type:Lensless",
        "month": "aug",
        "number": "16",
        "pages": "3056--3063",
        "pmid": "24964209",
        "publisher": "Royal Society of Chemistry",
        "title": "{A smartphone-based chip-scale microscope using ambient illumination}",
        "type": "article",
        "url": "www.rsc.org/loc",
        "volume": "14",
        "year": "2014"
    },
    "Liu2019": {
        "abstract": "{\\textcopyright} 2019 Optical Society of America. Lensless imaging based on multi-wavelength phase retrieval becomes a promising technology widely used as it has simple acquisition, miniaturized size and low-cost setup. However, measuring the sample-to-sensor distance with high accuracy, which is the key for high-resolution reconstruction, is still a challenge. In this work, we propose a multiwavelength criterion to realize autofocusing modulation, i.e., achieving much higher accuracy in determining the sample-to-sensor distance, compared to the conventional methods. Three beams in different spectrums are adopted to illuminate the sample, and the resulting holograms are recorded by a CCD camera. The patterns calculated by performing back propagation of the recorded holograms, with exhaustively searched sample-to-sensor distance value, are adopted to access the criterion. Image sharpness can be accessed and the optimal sample-to-sensor distance can be finely determined by targeting the valley of the curve given by the criterion. Through our novel multi-wavelength based autofocusing strategy and executing further phase retrieval process, high-resolution images can be finally retrieved. The applicability and robustness of our method is validated both in simulations and experiments. Our technique provides a useful tool for multi-wavelength lensless imaging under limited experimental conditions.",
        "author": "Liu, Jian and Zhao, Yixuan and Guo, Cheng and Zhao, Weisong and Zhang, Yutian and Guo, Changliang and Li, Haoyu",
        "doi": "10.1364/oe.27.023814",
        "issn": "1094-4087",
        "journal": "Optics Express",
        "keywords": "Mask:Holography,Mask:Multi-wavelength",
        "month": "aug",
        "number": "17",
        "pages": "23814",
        "pmid": "31510305",
        "publisher": "The Optical Society",
        "title": "{Robust autofocusing method for multi-wavelength lensless imaging}",
        "type": "article",
        "url": "https://doi.org/10.1364/OE.27.023814",
        "volume": "27",
        "year": "2019"
    },
    "Liu2019a": {
        "abstract": "We report a framework based on a generative adversarial network that performs high-fidelity color image reconstruction using a single hologram of a sample that is illuminated simultaneously by light at three different wavelengths. The trained network learns to eliminate missing-phase-related artifacts, and generates an accurate color transformation for the reconstructed image. Our framework is experimentally demonstrated using lung and prostate tissue sections that are labeled with different histological stains. This framework is envisaged to be applicable to point-of-care histopathology and presents a significant improvement in the throughput of coherent microscopy systems given that only a single hologram of the specimen is required for accurate color imaging.",
        "archiveprefix": "arXiv",
        "arxivid": "1907.06727",
        "author": "Liu, Tairan and Wei, Zhensong and Rivenson, Yair and Haan, Kevin and Zhang, Yibo and Wu, Yichen and Ozcan, Aydogan",
        "doi": "10.1002/jbio.201900107",
        "eprint": "1907.06727",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Liu et al. - 2019 - Deep learning\u2010based color holographic microscopy.pdf:pdf",
        "issn": "1864-063X",
        "journal": "Journal of Biophotonics",
        "keywords": "Algorithm:DNN,Application:Microscopy,Mask:Holography,Type:Lensless",
        "month": "nov",
        "number": "11",
        "pages": "e201900107",
        "pmid": "31309728",
        "publisher": "Wiley-VCH Verlag",
        "title": "{Deep learning\u2010based color holographic microscopy}",
        "type": "article",
        "url": "https://doi.org/10.1002/jbio.201900107 https://onlinelibrary.wiley.com/doi/abs/10.1002/jbio.201900107",
        "volume": "12",
        "year": "2019"
    },
    "Liu2021": {
        "abstract": "Multi-wavelength imaging diffraction system is a promising phase imaging technology due to its advantages of no mechanical movement and low complexity. In a multi-wavelength focused system, spectral bandwidth and dispersion correction are critical for high resolution reconstruction. Here, an optical setup for the multi-wavelength lensless diffraction imaging system with adaptive dispersion correction is proposed. Three beams with different wavelengths are adopted to illuminate the test object, and then the diffraction patterns are recorded by a image sensor. The chromatic correction is successfully realized by a robust refocusing technique. High-resolution images can be finally retrieved through phase retrieval algorithm. The effectiveness and reliability of our method is demonstrated in numerical simulation and experiments. The proposed method has the potential to be an alternative technology for quantitative biological imaging.",
        "author": "Liu, Yuanyuan and Liu, Qingwen and Li, You and Xu, Bingxin and Zhang, Junyong and He, Zuyuan",
        "doi": "10.1364/OE.419128",
        "issn": "1094-4087",
        "journal": "Optics Express",
        "keywords": "Biological imaging,Image quality,Imaging systems,Light transmission,Phase imaging,Phase retrieval",
        "month": "mar",
        "number": "5",
        "pages": "7197",
        "pmid": "33726225",
        "publisher": "The Optical Society",
        "title": "{High-resolution multi-wavelength lensless diffraction imaging with adaptive dispersion correction}",
        "type": "article",
        "url": "https://doi.org/10.1364/OE.419128 https://www.osapublishing.org/abstract.cfm?URI",
        "volume": "29",
        "year": "2021"
    },
    "Ludwig2021": {
        "abstract": "Scatter-plate microscopy (SPM) is a lensless imaging technique for high-resolution imaging through scattering media. So far, the method was demonstrated for spatially incoherent illumination and static scattering media. In this publication, we demonstrate that these restrictions are not necessary. We realized imaging with spatially coherent and spatially incoherent illumination. We further demonstrate that SPM is still a valid imaging method for scatter-plates, which change their scattering behaviour (i.e. the phase-shift) at each position on the plate continuously but independently from other positions. Especially we realized imaging through rotating ground glass diffusers.",
        "author": "Ludwig, Stephan and Ruchka, Pavel and Pedrini, Giancarlo and Peng, Xiang and Osten, Wolfgang",
        "doi": "10.1364/oe.412047",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Ludwig et al. - 2021 - Scatter-plate microscopy with spatially coherent illumination and temporal scatter modulation.pdf:pdf",
        "issn": "1094-4087",
        "journal": "Optics Express",
        "keywords": "Application:Microscopy,Mask:Diffuser,Mask:Scattering",
        "month": "feb",
        "number": "3",
        "pages": "4530",
        "pmid": "33771029",
        "publisher": "The Optical Society",
        "title": "{Scatter-plate microscopy with spatially coherent illumination and temporal scatter modulation}",
        "type": "article",
        "url": "https://doi.org/10.1364/OE.412047 https://www.osapublishing.org/abstract.cfm?URI",
        "volume": "29",
        "year": "2021"
    },
    "Lyu2019": {
        "abstract": "The problem of imaging through thick scattering media is encountered in many disciplines of science, ranging from mesoscopic physics to astronomy. Photons become diffusive after propagating through a scattering medium with an optical thickness of over 10 times the scattering mean free path. As a result, no image but only noise-like patterns can be directly formed. We propose a hybrid neural network for computational imaging through such thick scattering media, demonstrating the reconstruction of image information from various targets hidden behind a white polystyrene slab of 3 mm in thickness or 13.4 times the scattering mean free path. We also demonstrate that the target image can be retrieved with acceptable quality from a very small fraction of its scattered pattern, suggesting that the speckle pattern produced in this way is highly redundant. This leads to a profound question of how the information of the target being encoded into the speckle is to be addressed in future studies.",
        "author": "Lyu, Meng and Wang, Hao and Li, Guowei and Zheng, Shanshan and Situ, Guohai",
        "doi": "10.1117/1.ap.1.3.036002",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Lyu et al. - 2019 - Learning-based lensless imaging through optically thick scattering media.pdf:pdf",
        "issn": "2577-5421",
        "journal": "Advanced Photonics",
        "keywords": "Type:Lensless,computational imaging,deep learning,imaging through scattering media,neural network",
        "month": "jun",
        "number": "03",
        "pages": "1",
        "publisher": "SPIE-Intl Soc Optical Eng",
        "title": "{Learning-based lensless imaging through optically thick scattering media}",
        "type": "article",
        "url": "https://www.spiedigitallibrary.org/journals/Advanced-Photonics",
        "volume": "1",
        "year": "2019"
    },
    "Miller2020": {
        "abstract": "Light scattering is typically undesired in optical systems as it often introduces defects or otherwise negatively impacts device performance. However, rather than being a hindrance, scattering can also be exploited to achieve lensless imaging using a scattering mask instead of lenses to enable devices with low-cost, compact construction, and yet a large field of view. Lensless imaging can benefit greatly from the ability to dynamically tune the scattering pattern produced by the mask; however, this often results in increased complexity and cost. Herein, we propose and demonstrate particle-based reconfigurable scattering masks to dynamically tune light scattering for lensless imaging, enabling multishot image reconstruction. Disordered particle populations are tuned by rational application of electric fields without requiring bulky or expensive components. Several assembly motifs are explored and studied for optimal performance; in particular, gold nanowires chained between planar electrodes yield the best reconstruction quality and are the main focus in this study. The distinct gold nanowire based scattering masks achieve a complex wavelet structural similarity as low as 0.36. By leveraging the submicrometer thickness of particles and the resultant large optical memory effect, an angular field of view of \u00b145\u00b0 is demonstrated. The reconfigurable nature of the particle arrays enables multishot reconstruction which results in enhanced image quality and improved signal-to-noise ratios by up to 10-fold. These results suggest that reconfigurable particle masks could be a broadly applicable means of achieving dynamically tunable light scattering with potential applications in lensless microscopy or high-resolution imaging.",
        "author": "Miller, Jennifer R. and Wang, Cheng Yu and Keating, Christine D. and Liu, Zhiwen",
        "doi": "10.1021/acsnano.0c04490",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Miller et al. - 2020 - Particle-based reconfigurable scattering masks for lensless imaging.pdf:pdf",
        "issn": "1936086X",
        "journal": "ACS Nano",
        "keywords": "Mask:Programmable,Mask:Scattering",
        "month": "oct",
        "number": "10",
        "pages": "13038--13046",
        "pmid": "32929968",
        "publisher": "American Chemical Society",
        "title": "{Particle-based reconfigurable scattering masks for lensless imaging}",
        "type": "article",
        "url": "https://dx.doi.org/10.1021/acsnano.0c04490",
        "volume": "14",
        "year": "2020"
    },
    "Moazeni2021": {
        "abstract": "The advent of genetically encoded voltage and calcium indicators and optogenetic probes has unlocked unprecedented capabilities, including near-single-action-potential recording and stimulation with cell-type specificity. Optical functional imaging and optogenetics are delegated today primarily to large and expensive microscopes based on free-space optics. Integrating the microscope functionality into an implantable form factor remains an elusive goal. As a first step towards developing such a device, a variety of head-mounted 'miniscopes' have been demonstrated [1]. Using conventional lens-based optics, however, these devices consume considerable volume (more than 2cm3) to support field of views (FoVs) of sub-mm 2. To achieve a truly implantable microscope, a more volume-efficient device is necessary that spans a relatively large cortical area while maintaining a minimally-invasive form factor.",
        "author": "Moazeni, Sajjad and Pollmann, Eric H. and Boominathan, Vivek and Cardoso, Filipe A. and Robinson, Jacob T. and Veeraraghavan, Ashok and Shepard, Kenneth L.",
        "doi": "10.1109/ISSCC42613.2021.9365796",
        "file": ":Users/vivekboominathan/Dropbox/Research_local/Optica_Lensless_review/Papers/Rice/2021 SPAD FlatScope Columbia.pdf:pdf",
        "isbn": "9781728195490",
        "issn": "01936530",
        "journal": "Digest of Technical Papers - IEEE International Solid-State Circuits Conference",
        "keywords": "Mask:Amplitude mask,Sensor:SPAD",
        "pages": "288--290",
        "title": "{A Mechanically Flexible Implantable Neural Interface for Computational Imaging and Optogenetic Stimulation over 5.4 \u00d7 5.4 mm 2FoV}",
        "type": "article",
        "volume": "64",
        "year": "2021"
    },
    "Monakhova2020": {
        "abstract": "Hyperspectral imaging is useful for applications ranging from medical diagnostics to crop monitoring; however, traditional scanning hyperspectral imagers are prohibitively slow and expensive for widespread adoption. Snapshot techniques exist but are often confined to bulky bench-top setups or have low spatio-spectral resolution. In this paper, we propose a novel, compact, and inexpensive computational camera for snapshot hyperspectral imaging. Our system consists of a repeated spectral filter array placed directly on the image sensor and a diffuser placed close to the sensor. Each point in the world maps to a unique pseudorandom pattern on the spectral filter array, which encodes multiplexed spatio-spectral information. A sparsity-constrained inverse problem solver then recovers the hyperspectral volume with good spatio-spectral resolution. By using a spectral filter array, our hyperspectral imaging framework is flexible and can be designed with contiguous or non-contiguous spectral filters that can be chosen for a given application. We provide theory for system design, demonstrate a prototype device, and present experimental results with high spatio-spectral resolution. {\\textcopyright} 2020 Optical Society of America under the terms of the OSA Open Access Publishing Agreement",
        "archiveprefix": "arXiv",
        "arxivid": "2006.08565",
        "author": "Monakhova, Kristina and Yanny, Kyrollos and Aggarwal, Neerja and Waller, Laura",
        "doi": "10.1364/OPTICA.397214",
        "eprint": "2006.08565",
        "file": ":Users/vivekboominathan/Dropbox/Research_local/Optica_Lensless_review/Papers/Laura/2020 Optica Spectral DiffuserCam.pdf:pdf",
        "issn": "2334-2536",
        "journal": "Optica",
        "keywords": "Application:Hyperspectral,Mask:Diffuser",
        "month": "oct",
        "number": "10",
        "pages": "1298",
        "title": "{Spectral DiffuserCam: lensless snapshot hyperspectral imaging with a spectral filter array}",
        "type": "article",
        "url": "https://www.osapublishing.org/abstract.cfm?URI",
        "volume": "7",
        "year": "2020"
    },
    "Moon2009": {
        "abstract": "We demonstrate an integrated platform that merges a microfluidic chip with lensless imaging to target CD4+ T-lymphocyte counts for HIV point-of-care testing at resource-limited settings. The chips were designed and fabricated simply with a laser cutter without using expensive cleanroom equipment. To capture CD4+ T-lymphocytes from blood, anti-CD4 antibody was immobilized on only one side of the microfluidic chip. These captured cells were detected through an optically clear chip using a charge coupled device (CCD) sensor by lensless shadow imaging techniques. Gray scale image of the captured cells in a 24 mm \u00d7 4 mm \u00d7 50 $\\mu$m microfluidic chip was obtained by the lensless imaging platform. The automatic cell counting software enumerated the captured cells in 3 s. Captured cells were also imaged with a fluorescence microscope and manually counted to characterize functionality of the integrated platform. The integrated platform achieved 70.2 \u00b1 6.5% capture efficiency, 88.8 \u00b1 5.4% capture specificity for CD4+ T-lymphocytes, 96 \u00b1 1.6% CCD efficiency, and 83.5 \u00b1 2.4% overall platform performance (n",
        "author": "Moon, Sang Jun and Keles, Hasan Onur and Ozcan, Aydogan and Khademhosseini, Ali and H{\\ae}ggstrom, Edward and Kuritzkes, Daniel and Demirci, Utkan",
        "doi": "10.1016/j.bios.2009.03.037",
        "issn": "09565663",
        "journal": "Biosensors and Bioelectronics",
        "keywords": "CCD-based cell counter,HIV monitoring,POCT CD4+ monitoring,Type:Lensless",
        "month": "jul",
        "number": "11",
        "pages": "3208--3214",
        "pmid": "19467854",
        "publisher": "Elsevier",
        "title": "{Integrating microfluidics and lensless imaging for point-of-care testing}",
        "type": "article",
        "volume": "24",
        "year": "2009"
    },
    "Mudanyali2010": {
        "abstract": "Despite the rapid progress in optical imaging, most of the advanced microscopy modalities still require complex and costly set-ups that unfortunately limit their use beyond well equipped laboratories. In the meantime, microscopy in resource-limited settings has requirements significantly different from those encountered in advanced laboratories, and such imaging devices should be cost-effective, compact, light-weight and appropriately accurate and simple to be usable by minimally trained personnel. Furthermore, these portable microscopes should ideally be digitally integrated as part of a telemedicine network that connects various mobile health-care providers to a central laboratory or hospital. Toward this end, here we demonstrate a lensless on-chip microscope weighing \u223c46 grams with dimensions smaller than 4.2 cm \u00d7 4.2 cm \u00d7 5.8 cm that achieves sub-cellular resolution over a large field of view of \u223c24 mm2. This compact and light-weight microscope is based on digital in-line holography and does not need any lenses, bulky optical/mechanical components or coherent sources such as lasers. Instead, it utilizes a simple light-emitting-diode (LED) and a compact opto-electronic sensor-array to record lensless holograms of the objects, which then permits rapid digital reconstruction of regular transmission or differential interference contrast (DIC) images of the objects. Because this lensless incoherent holographic microscope has orders-of-magnitude improved light collection efficiency and is very robust to mechanical misalignments it may offer a cost-effective tool especially for telemedicine applications involving various global health problems in resource limited settings. {\\textcopyright} The Royal Society of Chemistry 2010.",
        "author": "Mudanyali, Onur and Tseng, Derek and Oh, Chulwoo and Isikman, Serhan O. and Sencan, Ikbal and Bishara, Waheb and Oztoprak, Cetin and Seo, Sungkyu and Khademhosseini, Bahar and Ozcan, Aydogan",
        "doi": "10.1039/c000453g",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Mudanyali et al. - 2010 - Compact, light-weight and cost-effective microscope based on lensless incoherent holography for telemedicine a.pdf:pdf",
        "issn": "14730189",
        "journal": "Lab on a Chip",
        "keywords": "Application:Microscopy",
        "number": "11",
        "pages": "1417--1428",
        "publisher": "Royal Society of Chemistry",
        "title": "{Compact, light-weight and cost-effective microscope based on lensless incoherent holography for telemedicine applications}",
        "type": "article",
        "volume": "10",
        "year": "2010"
    },
    "Nakamura2016": {
        "abstract": "Attractive revolutions of imaging technologies, such as Light Field Camera and Lensless Camera, are expected to innovate various imaging applications. We propose another technology to realize a lensless light-field imaging method. The device consists of an image sensor and a Fresnel zone aperture (FZA) slightly separated in a few millimeter spacing. Synthesized shadows of it with the incident light are detected and generate moir{\\'{e}} fringes interfering with another virtual FZA in a computer. Images are reconstructed by FFT of the fringes. Re-focusing is available by changing the size of the virtual FZA. We experimentally confirmed feasibility of the method by using a prototype which can reconstruct image at over 30 fps.",
        "author": "Nakamura, Yusuke and Shimano, Takeshi and Tajima, Kazuyuki and Sao, Mayu and Hoshizawa, Taku",
        "doi": "10.11485/ITETR.40.40.0_7",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Nakamura et al. - 2016 - Lensless Light-field Imaging with Fresnel Zone Aperture.pdf:pdf",
        "issn": "1342-6893",
        "keywords": "Mask:Amplitude mask,PSF:FZA",
        "pages": "7--8",
        "publisher": "The Institute of Image Information and Television Engineers",
        "title": "{Lensless Light-field Imaging with Fresnel Zone Aperture}",
        "type": "techreport",
        "year": "2016"
    },
    "Ozcan2008": {
        "abstract": "We experimentally and theoretically demonstrate the proof-of-principle of a new lens-free cell monitoring platform that involves using an opto-electronic sensor array to record the shadow image of cells onto the sensor plane. This technology can monitor/count cells over a field-of-view that is more than two orders of magnitude larger than that of a conventional light microscope. Furthermore, it does not require any mechanical scanning or optical elements, such as microscope objectives or lenses. We also show that this optical approach can conveniently be combined with microfluidic channels, enabling parallel on-chip monitoring of various different cell types, e.g., blood cells, NIH-3T3 fibroblasts, murine embryonic stem cells, AML-12 hepatocytes. An important application of this approach could be a miniaturized point-of-care technology to obtain CD4 T lymphocyte counts of HIV infected patients in resource limited settings. {\\textcopyright} The Royal Society of Chemistry.",
        "author": "Ozcan, Aydogan and Demirci, Utkan",
        "doi": "10.1039/B713695A",
        "issn": "1473-0197",
        "journal": "Lab Chip",
        "keywords": "Application:Microscopy,Mask:Bare Sensor",
        "month": "dec",
        "number": "1",
        "pages": "98--106",
        "pmid": "18094767",
        "publisher": "Royal Society of Chemistry",
        "title": "{Ultra wide-field lens-free monitoring of cells on-chip}",
        "type": "article",
        "url": "http://xlink.rsc.org/?DOI",
        "volume": "8",
        "year": "2008"
    },
    "Ozcan2016": {
        "abstract": "High-resolution optical microscopy has traditionally relied on high-magnification and high-numerical aperture objective lenses. In contrast, lensless microscopy can provide high-resolution images without the use of any focusing lenses, offering the advantages of a large field of view, high resolution, cost-effectiveness, portability, and depth-resolved three-dimensional (3D) imaging. Here we review various approaches to lensless imaging, as well as its applications in biosensing, diagnostics, and cytometry. These approaches include shadow imaging, fluorescence, holography, superresolution 3D imaging, iterative phase recovery, and color imaging. These approaches share a reliance on computational techniques, which are typically necessary to reconstruct meaningful images from the raw data captured by digital image sensors. When these approaches are combined with physical innovations in sample preparation and fabrication, lensless imaging can be used to image and sense cells, viruses, nanoparticles, and biomolecules. We conclude by discussing several ways in which lensless imaging and sensing might develop in the near future.",
        "author": "Ozcan, Aydogan and McLeod, Euan",
        "doi": "10.1146/annurev-bioeng-092515-010849",
        "file": ":Users/vivekboominathan/Dropbox/Research_local/Optica_Lensless_review/Papers/2016 Lensless Imaging and Sensing - Ozcan review - annual bioengineering.pdf:pdf",
        "issn": "15454274",
        "journal": "Annual Review of Biomedical Engineering",
        "keywords": "Application:Lab-on-chip,Application:Microscopy,Mask:Holography,Source:Review",
        "pages": "77--102",
        "pmid": "27420569",
        "title": "{Lensless Imaging and Sensing}",
        "type": "article",
        "volume": "18",
        "year": "2016"
    },
    "Pan2021": {
        "abstract": "We propose a preliminary lensless inference camera (LLI camera) specialized for object recognition. The LLI camera performs computationally efficient data preprocessing on the optically encoded pattern through the mask, rather than performing computationally expensive image reconstruction before inference. Therefore, the LLI camera avoids expensive computation and achieves real-time inference. This work proposes a new data preprocessing approach, named local binary patterns map generation, dedicated for optically encoded pattern through the mask. This preprocessing approach greatly improves encoded pattern&#x2019;s robustness to local disturbances in the scene, making the LLI camera&#x2019;s practical application possible. The performance of the LLI camera is analyzed through optical experiments on handwritten digit recognition and gender estimation under conditions with changing illumination and a moving target.",
        "author": "Pan, Xiuxi and Nakamura, Tomoya and Chen, Xiao and Yamaguchi, Masahiro",
        "doi": "10.1364/OE.416613",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Pan et al. - 2021 - Lensless inference camera incoherent object recognition through a thin mask with LBP map generation.pdf:pdf",
        "issn": "1094-4087",
        "journal": "Optics Express",
        "keywords": "Diffraction limit,Image analysis,Image processing,Image reconstruction,Image sensors,Optical sensing",
        "month": "mar",
        "number": "7",
        "pages": "9758",
        "pmid": "33820129",
        "publisher": "The Optical Society",
        "title": "{Lensless inference camera: incoherent object recognition through a thin mask with LBP map generation}",
        "type": "article",
        "url": "https://doi.org/10.1364/OE.416613 https://www.osapublishing.org/abstract.cfm?URI",
        "volume": "29",
        "year": "2021"
    },
    "Pang2010": {
        "abstract": "We report the implementation of a color-capable on-chip lensless microscope system, termed color optofluidic microscope (color OFM), and demonstrate imaging of double stained Caenorhabditis elegans with lacZ gene expression at a light intensity about 10 mW/cm2. {\\textcopyright} 2010 The Royal Society of Chemistry.",
        "author": "Pang, Shuo and Cui, Xiquan and Demodena, John and Wang, Ying Min and Sternberg, Paul and Yang, Changhuei",
        "doi": "10.1039/b919004j",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Pang et al. - 2010 - Implementation of a color-capable optofluidic microscope on a RGB CMOS color sensor chip substrate.pdf:pdf",
        "issn": "14730189",
        "journal": "Lab on a Chip",
        "keywords": "Application:Microfluidics,Mask:Shadow,Type:Lensless",
        "month": "feb",
        "number": "4",
        "pages": "411--414",
        "publisher": "Royal Society of Chemistry",
        "title": "{Implementation of a color-capable optofluidic microscope on a RGB CMOS color sensor chip substrate}",
        "type": "article",
        "url": "www.rsc.org/loc",
        "volume": "10",
        "year": "2010"
    },
    "Porat2016": {
        "abstract": "Flexible fiber-optic endoscopes provide a solution for imaging at depths beyond the reach of conventional microscopes. Current endoscopes require focusing and/or scanning mechanisms at the distal end, which limit miniaturization, frame-rate, and field of view. Alternative wavefront-shaping based lensless solutions are extremely sensitive to fiber-bending. We present a lensless, bend-insensitive, single-shot imaging approach based on speckle-correlations in fiber bundles that does not require wavefront shaping. Our approach computationally retrieves the target image by analyzing a single camera frame, exploiting phase information that is inherently preserved in propagation through convnetional fiber bundles. Unlike conventional fiber-based imaging, planar objects can be imaged at variable working distances, the resulting image is unpixelated and diffraction-limited, and miniaturization is limited only by the fiber diameter.",
        "author": "Porat, Amir and Andresen, Esben Ravn and Rigneault, Herv{\\'{e}} and Oron, Dan and Gigan, Sylvain and Katz, Ori",
        "doi": "10.1364/oe.24.016835",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Porat et al. - 2016 - Widefield lensless imaging through a fiber bundle via speckle correlations.pdf:pdf",
        "issn": "1094-4087",
        "journal": "Optics Express",
        "keywords": "Application:Endoscopy,Mask:Fiberoptic,Type:Lensless",
        "month": "jul",
        "number": "15",
        "pages": "16835",
        "pmid": "27464136",
        "publisher": "The Optical Society",
        "title": "{Widefield lensless imaging through a fiber bundle via speckle correlations}",
        "type": "article",
        "url": "http://dx.doi.org/10.1364/OE.24.016835",
        "volume": "24",
        "year": "2016"
    },
    "Ray2020": {
        "abstract": "The optical detection of nanoparticles, including viruses and bacteria, underpins many of the biological, physical and engineering sciences. However, due to their low inherent scattering, detection of these particles remains challenging, requiring complex instrumentation involving extensive sample preparation methods, especially when sensing is performed in liquid media. Here we present an easy-to-use, high-throughput, label-free and cost-effective method for detecting nanoparticles in low volumes of liquids (25 nL) on a disposable chip, using an acoustically actuated lens-free holographic system. By creating an ultrasonic standing wave in the liquid sample, placed on a low-cost glass chip, we cause deformations in a thin liquid layer (850 nm) containing the target nanoparticles (\u2265140 nm), resulting in the creation of localized lens-like liquid menisci. We also show that the same acoustic waves, used to create the nanolenses, can mitigate against non-specific, adventitious nanoparticle binding, without the need for complex surface chemistries acting as blocking agents.",
        "author": "Ray, Aniruddha and Khalid, Muhammad Arslan and Dem{\\v{c}}enko, Andriejus and Daloglu, Mustafa and Tseng, Derek and Reboud, Julien and Cooper, Jonathan M. and Ozcan, Aydogan",
        "doi": "10.1038/s41467-019-13802-1",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Ray et al. - 2020 - Holographic detection of nanoparticles using acoustically actuated nanolenses.pdf:pdf",
        "issn": "2041-1723",
        "journal": "Nature Communications",
        "keywords": "Mask:Holography,Type:Lensless",
        "month": "dec",
        "number": "1",
        "pages": "171",
        "pmid": "31949134",
        "publisher": "Nature Research",
        "title": "{Holographic detection of nanoparticles using acoustically actuated nanolenses}",
        "type": "article",
        "url": "https://doi.org/10.1038/s41467-019-13802-1 http://www.nature.com/articles/s41467-019-13802-1",
        "volume": "11",
        "year": "2020"
    },
    "Rego2021": {
        "abstract": "Lensless imaging is a new, emerging modality where image sensors utilize optical elements in front of the sensor to perform multiplexed imaging. There have been several recent papers to reconstruct images from lensless imagers, including methods that utilize deep learning for state-of-the-art performance. However, many of these methods require explicit knowledge of the optical element, such as the point spread function, or learn the reconstruction mapping for a single fixed PSF. In this paper, we explore a neural network architecture that performs joint image reconstruction and PSF estimation to robustly recover images captured with multiple PSFs from different cameras. Using adversarial learning, this approach achieves improved reconstruction results that do not require explicit knowledge of the PSF at test-time and shows an added improvement in the reconstruction model's ability to generalize to variations in the camera's PSF. This allows lensless cameras to be utilized in a wider range of applications that require multiple cameras without the need to explicitly train a separate model for each new camera.",
        "author": "Rego, Joshua D",
        "booktitle": "WACV",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Rego - 2021 - Robust Lensless Image Reconstruction via PSF Estimation.pdf:pdf",
        "keywords": "Algorithm:DNN",
        "pages": "403--412",
        "title": "{Robust Lensless Image Reconstruction via PSF Estimation}",
        "type": "inproceedings",
        "year": "2021"
    },
    "Reshetouski2020": {
        "abstract": "We introduce a lensless imaging framework for contemporary computer vision applications in long-wavelength infrared (LWIR). The framework consists of two parts: a novel lensless imaging method that utilizes the idea of local directional focusing for optimal binary sparse coding, and lensless imaging simulator based on Fresnel-Kirchhoff diffraction approximation. Our lensless imaging approach, besides being computationally efficient, is calibration-free and allows for wide FOV imaging. We employ our lensless imaging simulation software for optimizing reconstruction parameters and for synthetic image generation for CNN training. We demonstrate the advantages of our framework on a dual-camera system (RGB-LWIR lensless), where we perform CNN-based human detection using the fused RGB-LWIR data.",
        "author": "Reshetouski, Ilya and Oyaizu, Hideki and Nakamura, Kenichiro and Satoh, Ryuta and Ushiki, Suguru and Tadano, Ryuichi and Ito, Atsushi and Murayama, Jun",
        "booktitle": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "doi": "10.1007/978-3-030-58529-7_15",
        "file": ":Users/vivekboominathan/Dropbox/Research_local/Optica_Lensless_review/Papers/2020 ECCV Lensless LWIR from Sony.pdf:pdf",
        "isbn": "9783030585280",
        "issn": "16113349",
        "keywords": "Mask:Amplitude mask,PSF:Sparse-URA,Sensor:Thermal,Thickness:3.2mm",
        "pages": "237--253",
        "title": "{Lensless Imaging with Focusing Sparse URA Masks in Long-Wave Infrared and Its Application for Human Detection}",
        "type": "incollection",
        "url": "https://link.springer.com/10.1007/978-3-030-58529-7_15",
        "volume": "12364 LNCS",
        "year": "2020"
    },
    "Reshetouski2021": {
        "author": "Reshetouski, Ilya and Tadano, Ryuichi and Oyaizu, Hideki and Nakamura, Kenichiro and Murayama, Jun",
        "booktitle": "2021 IEEE International Conference on Computational Photography (ICCP)",
        "keywords": "Mask:Amplitude mask,PSF:Sparse-URA,Thickness:38.6mm",
        "publisher": "IEEE",
        "title": "{Lensless Mismatched Aspect Ratio Imaging}",
        "type": "inproceedings",
        "year": "2021"
    },
    "Rivenson2019": {
        "abstract": "Recent advances in deep learning have given rise to a new paradigm of holographic image reconstruction and phase recovery techniques with real-time performance. Through data-driven approaches, these emerging techniques have overcome some of the challenges associated with existing holographic image reconstruction methods while also minimizing the hardware requirements of holography. These recent advances open up a myriad of new opportunities for the use of coherent imaging systems in biomedical and engineering research and related applications.",
        "author": "Rivenson, Yair and Wu, Yichen and Ozcan, Aydogan",
        "doi": "10.1038/s41377-019-0196-0",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Rivenson, Wu, Ozcan - 2019 - Deep learning in holography and coherent imaging.pdf:pdf",
        "issn": "2047-7538",
        "journal": "Light: Science & Applications",
        "keywords": "Algorithm:DNN,Application:Microscopy,Mask:Holography,Type:Lensless",
        "month": "dec",
        "number": "1",
        "pages": "85",
        "publisher": "Nature Publishing Group",
        "title": "{Deep learning in holography and coherent imaging}",
        "type": "article",
        "url": "https://doi.org/10.1038/s41377-019-0196-0 http://www.nature.com/articles/s41377-019-0196-0",
        "volume": "8",
        "year": "2019"
    },
    "Sanz2017": {
        "abstract": "We report on a reduced cost, portable and compact prototype design of lensless holographic microscope with an illumination/detection scheme based on wavelength multiplexing, working with single hologram acquisition and using a fast convergence algorithm for image processing. All together, MISHELF (initials coming from Multi-Illumination Single-Holographic-Exposure Lensless Fresnel) microscopy allows the recording of three Fresnel domain diffraction patterns in a single camera snap-shot incoming from illuminating the sample with three coherent lights at once. Previous implementations have proposed an illumination/detection procedure based on a tuned (illumination wavelengths centered at the maximum sensitivity of the camera detection channels) configuration but here we report on a detuned (non-centered ones) scheme resulting in prototype miniaturization and cost reduction. Thus, MISHELF microscopy in combination with a novel and fast iterative algorithm allows high-resolution ($\\mu$m range) phase-retrieved (twin image elimination) quantitative phase imaging of dynamic events (video rate recording speed). The performance of this microscope prototype is validated through experiments using both amplitude (USAF resolution test) and complex (live swine sperm cells and flowing microbeads) samples. The proposed method becomes in an alternative instrument improving some capabilities of existing lensless microscopes.",
        "author": "Sanz, Mart{\\'{i}}n and Picazo-Bueno, Jos{\\'{e}} {\\'{A}}ngel and Granero, Luis and Garci{\\'{a} Javier and Mic{\\'{o} Vicente",
        "doi": "10.1038/srep43291",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Sanz et al. - 2017 - Compact, cost-effective and field-portable microscope prototype based on MISHELF microscopy(2).pdf:pdf",
        "issn": "20452322",
        "journal": "Scientific Reports",
        "keywords": "Application:Microscopy,Mask:Holography",
        "month": "feb",
        "number": "1",
        "pages": "1--12",
        "pmid": "28233829",
        "publisher": "Nature Publishing Group",
        "title": "{Compact, cost-effective and field-portable microscope prototype based on MISHELF microscopy}",
        "type": "article",
        "url": "www.nature.com/scientificreports/",
        "volume": "7",
        "year": "2017"
    },
    "Satat2017": {
        "abstract": "Lensless imaging is an important and challenging problem. One notable solution to lensless imaging is a single pixel camera which benefits from ideas central to compressive sampling. However, traditional single pixel cameras require many illumination patterns which result in a long acquisition process. Here we present a method for lensless imaging based on compressive ultrafast sensing. Each sensor acquisition is encoded with a different illumination pattern and produces a time series where time is a function of the photon's origin in the scene. Currently available hardware with picosecond time resolution enables time tagging photons as they arrive to an omnidirectional sensor. This allows lensless imaging with significantly fewer patterns compared to regular single pixel imaging. To that end, we develop a framework for designing lensless imaging systems that use ultrafast detectors. We provide an algorithm for ideal sensor placement and an algorithm for optimized active illumination patterns. We show that efficient lensless imaging is possible with ultrafast measurement and compressive sensing. This paves the way for novel imaging architectures and remote sensing in extreme situations where imaging with a lens is not possible.",
        "archiveprefix": "arXiv",
        "arxivid": "1610.05834",
        "author": "Satat, Guy and Tancik, Matthew and Raskar, Ramesh",
        "doi": "10.1109/TCI.2017.2684624",
        "eprint": "1610.05834",
        "issn": "2333-9403",
        "journal": "IEEE Transactions on Computational Imaging",
        "month": "sep",
        "number": "3",
        "pages": "398--407",
        "publisher": "Institute of Electrical and Electronics Engineers (IEEE)",
        "title": "{Lensless Imaging With Compressive Ultrafast Sensing}",
        "type": "article",
        "url": "https://ieeexplore.ieee.org/document/7882664/",
        "volume": "3",
        "year": "2017"
    },
    "Seo2009": {
        "abstract": "We experimentally illustrate a lensfree holographic imaging platform to perform on-chip cytometry. By controlling the spatial coherence of the illumination source, we record a 2D holographic diffraction pattern of each cell or micro-particle on a chip using a high resolution sensor array that has \u223c2 m pixel size. The recorded holographic image is then processed by using a custom developed decision algorithm for matching the detected hologram texture to existing library images for on-chip characterization and counting of a heterogeneous solution of interest. The holographic diffraction signature of any microscopic object is significantly different from the classical diffraction pattern of the same object. It improves the signal to noise ratio and the signature uniformity of the cell patterns; and also exhibits much better sensitivity for on-chip imaging of weakly scattering phase objects such as small bacteria or cells. We verify significantly improved performance of this holographic on-chip cytometry approach by automatically characterizing heterogeneous solutions of red blood cells, yeast cells, E. coli and various sized micro-particles without the use of any lenses or microscope objectives. This lensless on-chip holography platform will especially be useful for point-of-care cytometry and diagnostics applications involving e.g., infectious diseases such as HIV or malaria. {\\textcopyright} 2009 The Royal Society of Chemistry.",
        "author": "Seo, Sungkyu and Su, Ting Wei and Tseng, Derek K. and Erlinger, Anthony and Ozcan, Aydogan",
        "doi": "10.1039/b813943a",
        "issn": "14730189",
        "journal": "Lab on a Chip",
        "keywords": "Application:Microscopy,Mask:Bare Sensor,Mask:Holography",
        "month": "mar",
        "number": "6",
        "pages": "777--787",
        "pmid": "19255659",
        "publisher": "Royal Society of Chemistry",
        "title": "{Lensfree holographic imaging for on-chip cytometry and diagnostics}",
        "type": "article",
        "url": "http://xlink.rsc.org/?DOI",
        "volume": "9",
        "year": "2009"
    },
    "Shekel2020": {
        "abstract": "Lensless flexible fiber-bundle based endoscopes allow imaging at depths beyond the reach of conventional microscopes with a minimal footprint. These multicore fibers provide a simple solution for widefield fluorescent imaging when the target is adjacent to the fiber facet. However, they suffer from a very limited working distance and out-of-focus background. Here, we carefully study the dynamic speckle illumination patterns generated by bending a commercial fiber-bundle, and show that they can be exploited to allow extended working distance and background rejection, using a super-resolution fluctuations imaging (SOFI) analysis of multiple frames, without the addition of any optical elements.",
        "archiveprefix": "arXiv",
        "arxivid": "2004.10960",
        "author": "Shekel, Noam and Katz, Ori",
        "doi": "10.1364/OL.395839",
        "eprint": "2004.10960",
        "issn": "0146-9592",
        "journal": "Optics Letters",
        "keywords": "Application:Endoscopy,Mask:Fiberoptic",
        "month": "aug",
        "number": "15",
        "pages": "4288",
        "pmid": "32735281",
        "publisher": "arXiv",
        "title": "{Using fiber-bending-generated speckles for improved working distance and background rejection in lensless micro-endoscopy}",
        "type": "article",
        "url": "https://www.osapublishing.org/viewmedia.cfm?uri",
        "volume": "45",
        "year": "2020"
    },
    "Shimano2018": {
        "abstract": "We propose a new type of lensless camera enabling light-field imaging for focusing after image capture and show its feasibilities with some prototyping. The camera basically consists only of an image sensor and Fresnel zone aperture (FZA). Point sources making up the subjects to be captured cast overlapping shadows of the FZA on the sensor, which result in overlapping straight moir&#x00E9; fringes due to multiplication of another virtual FZA in the computer. The fringes generate a captured image by two-dimensional fast Fourier transform. Refocusing is possible by adjusting the size of the virtual FZA. We found this imaging principle is quite analogous to a coherent hologram. Not only the functions of still cameras but also of video cameras are confirmed experimentally by using the prototyped cameras.",
        "author": "Shimano, Takeshi and Nakamura, Yusuke and Tajima, Kazuyuki and Sao, Mayu and Hoshizawa, Taku",
        "doi": "10.1364/ao.57.002841",
        "issn": "1559-128X",
        "journal": "Applied Optics",
        "keywords": "Application:Lightfield,Mask:Amplitude mask,PSF:FZA",
        "month": "apr",
        "number": "11",
        "pages": "2841",
        "pmid": "29714287",
        "publisher": "The Optical Society",
        "title": "{Lensless light-field imaging with Fresnel zone aperture: quasi-coherent coding}",
        "type": "article",
        "volume": "57",
        "year": "2018"
    },
    "Shin2019": {
        "abstract": "Ultra-miniaturized microendoscopes are vital for numerous biomedical applications. Such minimally invasive imagers allow for navigation into hard-to-reach regions and observation of deep brain activity in freely moving animals. Conventional solutions use distal microlenses. However, as lenses become smaller and less invasive, they develop greater aberrations and restricted fields of view. In addition, most of the imagers capable of variable focusing require mechanical actuation of the lens, increasing the distal complexity and weight. Here, we demonstrate a distal lens-free approach to microendoscopy enabled by computational image recovery. Our approach is entirely actuation free and uses a single pseudorandom spatial mask at the distal end of a multicore fiber. Experimentally, this lensless approach increases the space-bandwidth product, i.e., field of view divided by resolution, by threefold over a best-case lens-based system. In addition, the microendoscope demonstrates color resolved imaging and refocusing to 11 distinct depth planes from a single camera frame without any actuated parts.",
        "author": "Shin, Jaewook and Tran, Dung N. and Stroud, Jasper R. and Chin, Sang and Tran, Trac D. and Foster, Mark A.",
        "doi": "10.1126/sciadv.aaw5595",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Shin et al. - 2019 - A minimally invasive lens-free computational microendoscope.pdf:pdf",
        "issn": "2375-2548",
        "journal": "Science Advances",
        "keywords": "Application:Endoscopy",
        "month": "dec",
        "number": "12",
        "pages": "eaaw5595",
        "pmid": "31840055",
        "publisher": "American Association for the Advancement of Science",
        "title": "{A minimally invasive lens-free computational microendoscope}",
        "type": "article",
        "url": "http://advances.sciencemag.org/ https://advances.sciencemag.org/lookup/doi/10.1126/sciadv.aaw5595",
        "volume": "5",
        "year": "2019"
    },
    "Singh2017": {
        "abstract": "Scattering media, such as diffused glass and biological tissue, are usually treated as obstacles in imaging. To cope with the random phase introduced by a turbid medium, most existing imaging techniques recourse to either phase compensation by optical means or phase recovery using iterative algorithms, and their applications are often limited to two-dimensional imaging. In contrast, we utilize the scattering medium as an unconventional imaging lens and exploit its lens-like properties for lensless three-dimensional (3D) imaging with diffraction-limited resolution. Our spatially incoherent lensless imaging technique is simple and capable of variable focusing with adjustable depths of focus that enables depth sensing of 3D objects that are concealed by the diffusing medium. Wide-field imaging with diffraction-limited resolution is verified experimentally by a single-shot recording of the 1951 USAF resolution test chart, and 3D imaging and depth sensing are demonstrated by shifting focus over axially separated objects.",
        "author": "Singh, Alok Kumar and Naik, Dinesh N. and Pedrini, Giancarlo and Takeda, Mitsuo and Osten, Wolfgang",
        "doi": "10.1038/lsa.2016.219",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Singh et al. - 2017 - Exploiting scattering media for exploring 3D objects.pdf:pdf",
        "issn": "20477538",
        "journal": "Light: Science and Applications",
        "keywords": "3D imaging,Intensity correlation technique,Lensless imaging,Scattering media",
        "month": "sep",
        "number": "2",
        "pages": "e16219--e16219",
        "publisher": "Nature Publishing Group",
        "title": "{Exploiting scattering media for exploring 3D objects}",
        "type": "article",
        "url": "www.nature.com/lsa",
        "volume": "6",
        "year": "2017"
    },
    "Singh2017a": {
        "abstract": "Scattering media have always been looked upon as an obstacle in imaging. Various methods, ranging from holography to phase compensation as well as to correlation techniques, have been proposed to cope with this obstacle. We, on the other hand, have a different understanding about the role of the diffusing media. In this paper we propose and demonstrate a 'scatter-plate microscope' that utilizes the diffusing property of the random medium for imaging micro structures with diffraction-limited resolution. The ubiquitous property of the speckle patterns permits to exploit the scattering medium as an ultra-thin lensless microscope objective with a variable focal length and a large working distance. The method provides a light, flexible and cost effective imaging device as an alternative to conventional microscope objectives. In principle, the technique is also applicable to lensless imaging in UV and X-ray microscopy. Experiments were performed with visible light to demonstrate the microscopic imaging of USAF resolution test target and a biological sample with varying numerical aperture (NA) and magnifications.",
        "author": "Singh, Alok Kumar and Pedrini, Giancarlo and Takeda, Mitsuo and Osten, Wolfgang",
        "doi": "10.1038/s41598-017-10767-3",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Singh et al. - 2017 - Scatter-plate microscope for lensless microscopy with diffraction limited resolution.pdf:pdf",
        "issn": "20452322",
        "journal": "Scientific Reports",
        "keywords": "Application:Microscopy,Mask:Diffuser,Mask:Scattering",
        "month": "dec",
        "number": "1",
        "pages": "1--8",
        "pmid": "28878361",
        "publisher": "Nature Publishing Group",
        "title": "{Scatter-plate microscope for lensless microscopy with diffraction limited resolution}",
        "type": "article",
        "url": "www.nature.com/scientificreports/",
        "volume": "7",
        "year": "2017"
    },
    "Sinha2017": {
        "abstract": "Deep learning has been proven to yield reliably generalizable answers to numerous classification and decision tasks. Here, we demonstrate for the first time, to our knowledge, that deep neural networks (DNNs) can be trained to solve inverse problems in computational imaging. We experimentally demonstrate a lens-less imaging system where a DNN was trained to recover a phase object given a raw intensity image recorded some distance away.",
        "archiveprefix": "arXiv",
        "arxivid": "1702.08516",
        "author": "Sinha, Ayan and Lee, Justin and Li, Shuai and Barbastathis, George",
        "doi": "10.1364/OPTICA.4.001117",
        "eprint": "1702.08516",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Sinha et al. - 2017 - Lensless computational imaging through deep learning.pdf:pdf",
        "issn": "2334-2536",
        "journal": "Optica",
        "keywords": "(1004996) Pattern recognition,(1005070) Phase retrieval,(1101758) Computational imaging,Algorithm:DNN,OCIS codes: (1003190) Inverse problems,Type:Lensless",
        "month": "sep",
        "number": "9",
        "pages": "1117",
        "publisher": "arXiv",
        "title": "{Lensless computational imaging through deep learning}",
        "type": "article",
        "url": "https://doi.org/10.1364/OPTICA.4.001117 https://www.osapublishing.org/abstract.cfm?URI",
        "volume": "4",
        "year": "2017"
    },
    "Situ2004": {
        "abstract": "A lensless optical security system based on computer generated phase only masks is proposed in the present paper. These masks are located at determined positions along the direction of propagation so as to decrypt the target image. These positions coordinates are used as encoding parameters as well as the wavelength in the encryption process. Compared with previous studies, the proposed system has three significant advantages: first, it is lensless and therefore can minimize the hardware requirement and is much easier to implement. Second, the proposed system uses the wavelength and the position parameters besides the phase codes as additional keys and consequently achieves much higher security. Finally, the encrypted data can be directly transmitted via communication lines and then decrypted with the correct wavelength and the position parameters at the receiver. Applications and implementation considerations of the proposed system are also discussed. {\\textcopyright} 2004 Elsevier B.V. All rights reserved.",
        "author": "Situ, Guohai and Zhang, Jingjuan",
        "doi": "10.1016/j.optcom.2004.01.002",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Situ, Zhang - 2004 - A lensless optical security system based on computer-generated phase only masks.pdf:pdf",
        "issn": "00304018",
        "journal": "Optics Communications",
        "keywords": "Optical data processing,Optical encryption,Phase retrieval,Type:Lensless",
        "month": "mar",
        "number": "1-6",
        "pages": "115--122",
        "publisher": "North-Holland",
        "title": "{A lensless optical security system based on computer-generated phase only masks}",
        "type": "article",
        "volume": "232",
        "year": "2004"
    },
    "Song2020": {
        "abstract": "We report an angle-tilted, wavelength-multiplexed ptychographic modulation approach for multispectral lensless on-chip microscopy. In this approach, we illuminate the specimen with lights at 5 wavelengths simultaneously. A prism is added at the illumination path for spectral dispersion. Lightwaves at different wavelengths, thus, hit the specimen at slightly different incident angles, breaking the ambiguities in mixed state ptychographic reconstruction. At the detection path, we place a thin diffuser in-between the specimen and the monochromatic image sensor for encoding the spectral information into 2D intensity measurements. By scanning the sample to different x-y positions, we acquire a sequence of monochromatic images for reconstructing the 5 complex object profiles at the 5 wavelengths. An up-sampling procedure is integrated into the recovery process to bypass the resolution limit imposed by the imager pixel size. We demonstrate a half-pitch resolution of 0.55 \u00b5m using an image sensor with 1.85-\u00b5m pixel size. We also demonstrate quantitative and high-quality multispectral reconstructions of stained tissue sections for digital pathology applications.",
        "author": "Song, Pengming and Wang, Ruihai and Zhu, Jiakai and Wang, Tianbo and Bian, Zichao and Zhang, Zibang and Hoshino, Kazunori and Murphy, Michael and Jiang, Shaowei and Guo, Chengfei and Zheng, Guoan",
        "doi": "10.1364/OL.394923",
        "issn": "0146-9592",
        "journal": "Optics Letters",
        "keywords": "Application:Hyperspectral",
        "month": "jul",
        "number": "13",
        "pages": "3486",
        "pmid": "32630878",
        "publisher": "arXiv",
        "title": "{Super-resolved multispectral lensless microscopy via angle-tilted, wavelength-multiplexed ptychographic modulation}",
        "type": "article",
        "url": "https://www.osapublishing.org/viewmedia.cfm?uri",
        "volume": "45",
        "year": "2020"
    },
    "Stork2013": {
        "abstract": "We describe a new class of lensless, ultra-miniature computational imagers and image sensors employing special optical phase gratings integrated with CMOS photodetector matrices. Because such imagers have no lens, they are ultra- miniature (\u223c100 $\\mu$m), have large effective depth of field (1 mm to infinity), and are very inexpensive (a few Euro cents). The grating acts as a two-dimensional visual \u201cchirp\u201d and preserves image power throughout the Fourier plane (and hence preserves image information); the final digital image is not captured as in a traditional camera but instead computed from raw photodetector signals. The novel representation at the photodetectors demands that algorithms such as deconvolution, Bayesian estimation, or matrix inversion with Tikhonov regularization be used to compute the image, each having different bandwidth, space and computational complexities for a given image fidelity. Such imaging architectures can also be tailored to extract application-specific information or compute decisions (rather than compute an image) based on the optical signal. In most cases, both the phase grating and the signal processing can be optimized for the information in the visual field and the task at hand. Our sensor design methodology relies on modular parallel and computationally efficient software tools for simulating optical diffraction, for CAD design and layout of gratings themselves, and for sensor signal processing. These sensors are so small they should find use in endoscopy, medical sensing, machine inspection, surveillance and the Internet of Things, and are so inexpensive that they should find use in distributed network applications and in a number of single-use scenarios, for instance in military theaters and hazardous natural and industrial conditions.",
        "author": "Stork, David G. and Gill, Patrick R.",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Stork, Gill - 2013 - Lensless Ultra-Miniature CMOS Computational Imagers and Sensors.pdf:pdf",
        "isbn": "978-1-61208-296-7",
        "issn": "2308-4405",
        "journal": "SENSORCOMM 2013: The Seventh International Conference on Sensor Technologies and Applications",
        "keywords": "Mask:Phase gratings",
        "pages": "186--190",
        "title": "{Lensless Ultra-Miniature CMOS Computational Imagers and Sensors}",
        "type": "article",
        "url": "http://www.thinkmind.org/index.php?view",
        "year": "2013"
    },
    "Tajima2017": {
        "abstract": "We have been proposing lensless light-field imaging with Fresnel zone aperture (FZA) in front of an image sensor in a few millimeter spacing. Synthesized shadows of real FZA with the incident light generate moir{\\'{e}} fringes interfering with another virtual FZA in a computer and result in reconstructed images by simple Fast Fourier Transformation (FFT). In order to obtain clear images in this configuration, it is necessary to cancel several kinds of noise component in the detected image signals. We describe details of the process and discuss its effectiveness theoretically and experimentally in this paper.",
        "author": "Tajima, Kazuyuki and Shimano, Takeshi and Nakamura, Yusuke and Sao, Mayu and Hoshizawa, Taku",
        "booktitle": "2017 IEEE International Conference on Computational Photography (ICCP)",
        "doi": "10.1109/ICCPHOT.2017.7951485",
        "isbn": "978-1-5090-5745-0",
        "keywords": "Application:Lightfield,Mask:Amplitude mask,PSF:FZA",
        "month": "may",
        "pages": "1--7",
        "publisher": "IEEE",
        "title": "{Lensless light-field imaging with multi-phased fresnel zone aperture}",
        "type": "inproceedings",
        "url": "http://ieeexplore.ieee.org/document/7951485/",
        "year": "2017"
    },
    "Tan2018": {
        "abstract": "Camera-based face detection and verification have advanced to the point where they are ready to be integrated into myriad applications, from household appliances to Internet of Things devices to drones. Many of these applications impose stringent constraints on the form-factor, weight, and cost of the camera package that cannot be met by current-generation lens-based imagers. Lensless imaging systems provide an increasingly promising alternative that radically changes the form-factor and reduces the weight and cost of a camera system. However, lensless imagers currently cannot offer the same image resolution and clarity of their lens-based counterparts. This paper details a first-of-its-kind evaluation of the potential and efficacy of lensless imaging systems for face detection and verification. We propose the usage of existing deep learning techniques for face detection and verification that account for the resolution, noise, and artifacts inherent in today's lensless cameras. We demonstrate that both face detection and verification can be performed with high accuracy from the images acquired from lensless cameras, which paves the way to their integration into new applications. A key component of our study is a dataset of 24 112 lensless camera images captured using FlatCam of 88 subjects in a range of different operating conditions.",
        "author": "Tan, Jasper and Niu, Li and Adams, Jesse K. and Boominathan, Vivek and Robinson, Jacob T. and Baraniuk, Richard G. and Veeraraghavan, Ashok",
        "doi": "10.1109/tci.2018.2889933",
        "file": ":Users/vivekboominathan/Dropbox/Research_local/Optica_Lensless_review/Papers/Rice/2019 Face Detection with FlatCam.pdf:pdf",
        "issn": "2573-0436",
        "journal": "IEEE Transactions on Computational Imaging",
        "keywords": "Application:Inference,Mask:Amplitude mask",
        "number": "2",
        "pages": "180--194",
        "publisher": "IEEE",
        "title": "{Face Detection and Verification Using Lensless Cameras}",
        "type": "article",
        "volume": "5",
        "year": "2018"
    },
    "Tan2020": {
        "abstract": "The standard pipeline for many vision tasks uses a conventional camera to capture an image that is then passed to a digital processor for information extraction. In some deployments, such as private locations, the captured digital imagery contains sensitive information exposed to digital vulnerabilities such as spyware, Trojans, etc. However, in many applications, the full imagery is unnecessary for the vision task at hand. In this paper we propose an optical and analog system that preprocesses the light from the scene before it reaches the digital imager to destroy sensitive information. We explore analog and optical encodings consisting of easily implementable operations such as convolution, pooling, and quantization. We perform a case study to evaluate how such encodings can destroy face identity information while preserving enough information for face detection. The encoding parameters are learned via an alternating optimization scheme based on adversarial learning with deep neural networks. We name our system CAnOPIC (Camera with Analog and Optical Privacy-Integrating Computations) and show that it has better performance in terms of both privacy and utility than conventional optical privacy-enhancing methods such as blurring and pixelation.",
        "author": "Tan, Jasper and Khan, Salman S. and Boominathan, Vivek and Byrne, Jeffrey and Baraniuk, Richard and Mitra, Kaushik and Veeraraghavan, Ashok",
        "doi": "10.1109/ICME46284.2020.9102956",
        "file": ":Users/vivekboominathan/Dropbox/Research_local/Optica_Lensless_review/Papers/Rice/2020 CAnOPIC.pdf:pdf",
        "isbn": "9781728113319",
        "issn": "1945788X",
        "journal": "Proceedings - IEEE International Conference on Multimedia and Expo",
        "keywords": "Application:Privacy",
        "pages": "0--5",
        "title": "{CANOPIC: Pre-digital privacy-enhancing encodings for computer vision}",
        "type": "article",
        "volume": "2020-July",
        "year": "2020"
    },
    "Tobon-Maya2021": {
        "abstract": "In this work, the design, construction, and testing of the most cost-effective digital lensless holographic microscope to date are presented. The architecture of digital lensless holographic microscopy (DLHM) is built by means of a 3D-printed setup and utilizing off-the-shelf materials to produce a DLHM microscope costing US$52.82. For the processing of the recorded in-line holograms an open-source software specifically developed to process this type of recordings is utilized. The presented DLHM setup has all the degrees of freedom needed to achieve different fields of view, levels of spatial resolution, and 2D-scanning of the sample. The feasibility of the presented platform is tested by imaging non- and bio-samples; resolution test targets, a section of the head of a Drosophila Melanogaster Fly, red blood cells, and cheek cells are imaged on the built microscope.",
        "author": "Tobon-Maya, Heberley and Zapata-Valencia, Samuel and Zora-Guzm{\\'{a}}n, Erick and Buitrago-Duque, Carlos and Garcia-Sucerquia, Jorge",
        "doi": "10.1364/ao.405605",
        "issn": "1559-128X",
        "journal": "Applied Optics",
        "keywords": "Application:Microscopy,Mask:Holography",
        "month": "feb",
        "number": "4",
        "pages": "A205",
        "pmid": "33690371",
        "publisher": "The Optical Society",
        "title": "{Open-source, cost-effective, portable, 3D-printed digital lensless holographic microscope}",
        "type": "article",
        "url": "https://www.osapublishing.org/viewmedia.cfm?uri",
        "volume": "60",
        "year": "2021"
    },
    "Vercruysse2015": {
        "abstract": "A compelling clinical need exists for inexpensive, portable haematology analyzers that can be utilized at the point-of-care in emergency settings or in resource-limited settings. Development of a label-free, microfluidic blood analysis platform is the first step towards such a miniaturized, cost-effective system. Here we assemble a compact lens-free in-line holographic microscope and employ it to image blood cells flowing in a microfluidic chip, using a high-speed camera and stroboscopic illumination. Numerical reconstruction of the captured holograms allows classification of unlabeled leukocytes into three main subtypes: lymphocytes, monocytes and granulocytes. A scale-space recognition analysis to evaluate cellular size and internal complexity is also developed and used to build a 3-part leukocyte differential. The lens-free image-based classification is compared to the 3-part white blood cell differential generated by using a conventional analyzer on the same blood sample and is found to be in good agreement with it.",
        "author": "Vercruysse, Dries and Dusa, Alexandra and Stahl, Richard and Vanmeerbeeck, Geert and {De Wijs Koen and Liu, Chengxun and Prodanov, Dimiter and Peumans, Peter and Lagae, Liesbet",
        "doi": "10.1039/c4lc01131g",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Vercruysse et al. - 2015 - Three-part differential of unlabeled leukocytes with a compact lens-free imaging flow cytometer.pdf:pdf",
        "issn": "14730189",
        "journal": "Lab on a Chip",
        "keywords": "Application:Microscopy,Mask:Holography,Type:Lensless",
        "month": "feb",
        "number": "4",
        "pages": "1123--1132",
        "pmid": "25537881",
        "publisher": "Royal Society of Chemistry",
        "title": "{Three-part differential of unlabeled leukocytes with a compact lens-free imaging flow cytometer}",
        "type": "article",
        "url": "www.rsc.org/loc",
        "volume": "15",
        "year": "2015"
    },
    "Wang2009": {
        "abstract": "We present a pixel-scale CMOS sensor for near-field, lensless 3D imaging. This angle-sensitive pixel (ASP) uses local, stacked diffraction gratings over a photodiode to discriminate the incident angle of incoming light. The ASPs, measuring 20$\\mu$m wide and 40$\\mu$m long, have been built in an unmodified 130nm CMOS process. Metal wiring layers provide the required gratings, while intrinsic pn-junctions act as photodiodes. We present operating principles and design considerations of the ASP, as well as results demonstrating desired angle sensitivity. Arrays of ASPs enable lensless microscale imaging that reconstructs the 3-dimensional structure of light sources. {\\textcopyright} 2009 IEEE.",
        "author": "Wang, Albert and Gill, Patrick and Molnar, Alyosha",
        "booktitle": "Proceedings of the Custom Integrated Circuits Conference",
        "doi": "10.1109/CICC.2009.5280840",
        "isbn": "9781424440726",
        "issn": "08865930",
        "keywords": "Sensor:ASP",
        "pages": "371--374",
        "title": "{Angle sensitive pixels in CMOS for lensless 3D imaging}",
        "type": "inproceedings",
        "year": "2009"
    },
    "White2020": {
        "abstract": "The need for lightweight, miniature imaging systems is becoming increasingly prevalent in light of the development of wearable electronics, IoT devices, and drones. Computational imaging enables new types of imaging systems that replace standard optical components like lenses with cleverly designed computational processes. Traditionally, many of these types of systems use conventional complementary metal oxide semiconductor (CMOS) or charge coupled device (CCD) sensors for data collection. While this allows for rapid development of large-scale systems, the lack of system-sensor co-design limits the compactness and performance. Here we propose integrated photonics as a candidate platform for the implementation of such co-integrated systems. Using grating couplers and co-designed computational processing in lieu of a lens, we demonstrate the use of silicon photonics as a viable platform for computational imaging with a prototype lensless imaging device. The proof-of-concept device has 20 sensors and a 45-degree field of view, and its optics and sensors are contained within a 2,000 $\\mu$m \u00d7 200 $\\mu$m \u00d7 20 $\\mu$m volume.",
        "author": "White, Alexander and Khial, Parham and Salehi, Fariborz and Hassibi, Babak and Hajimiri, Ali",
        "doi": "10.1038/s41598-020-58027-1",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/White et al. - 2020 - A Silicon Photonics Computational Lensless Active-Flat-Optics Imaging System.pdf:pdf",
        "issn": "20452322",
        "journal": "Scientific Reports",
        "month": "dec",
        "number": "1",
        "pages": "1--9",
        "pmid": "32015358",
        "publisher": "Nature Research",
        "title": "{A Silicon Photonics Computational Lensless Active-Flat-Optics Imaging System}",
        "type": "article",
        "url": "https://doi.org/10.1038/s41598-020-58027-1",
        "volume": "10",
        "year": "2020"
    },
    "Witte2014": {
        "abstract": "Lensless imaging is an approach to microscopy in which a high-resolution image of an object is reconstructed from one or more measured diffraction patterns, providing a solution in situations where the use of imaging optics is not possible. However, current lensless imaging methods are typically limited by the need for a light source with a narrow, stable and accurately known spectrum. We have developed a general approach to lensless imaging without spectral bandwidth limitations or sample requirements. We use two time-delayed coherent light pulses and show that scanning the pulse-to-pulse time delay allows the reconstruction of diffraction-limited images for all the spectral components in the pulse. In addition, we introduce an iterative phase retrieval algorithm that uses these spectrally resolved Fresnel diffraction patterns to obtain high-resolution images of complex extended objects. We demonstrate this two-pulse imaging method with octave-spanning visible light sources, in both transmission and reflection geometries, and with broadband extreme-ultraviolet radiation from a high-harmonic generation source. Our approach enables effective use of low-flux ultra-broadband sources, such as table-top high-harmonic generation systems, for high-resolution imaging. {\\textcopyright} 2014 CIOMP. All rights reserved.",
        "author": "Witte, Stefan and Tenner, Vasco T. and Noom, Daniel We and Eikema, Kjeld Se",
        "doi": "10.1038/lsa.2014.44",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Witte et al. - 2014 - Lensless diffractive imaging with ultra-broadband table-top sources From infrared to extreme-ultraviolet wavelengt.pdf:pdf",
        "issn": "20477538",
        "journal": "Light: Science and Applications",
        "keywords": "Type:Lensless",
        "month": "mar",
        "number": "3",
        "pages": "163",
        "publisher": "Nature Publishing Group",
        "title": "{Lensless diffractive imaging with ultra-broadband table-top sources: From infrared to extreme-ultraviolet wavelengths}",
        "type": "article",
        "url": "www.nature.com/lsa",
        "volume": "3",
        "year": "2014"
    },
    "Wu2014": {
        "abstract": "Light transport has been analyzed extensively, in both the primal domain and the frequency domain. Frequency analyses often provide intuition regarding effects introduced by light propagation and interaction with optical elements; such analyses encourage optimal designs of computational cameras that efficiently capture tailored visual information. However, previous analyses have relied on instantaneous propagation of light, so that the measurement of the time dynamics of light\u2013scene interaction, and any resulting information transfer, is precluded. In this paper, we relax the common assumption that the speed of light is infinite. We analyze free space light propagation in the frequency domain considering spatial, temporal, and angular light variation. Using this analysis, we derive analytic expressions for information transfer between these dimensions and show how this transfer can be exploited for designing a new lensless imaging system. With our frequency analysis, we also derive performance bounds for the proposed computational camera architecture and provide a mathematical framework that will also be useful for future ultra-fast computational imaging systems.",
        "author": "Wu, Di and Wetzstein, Gordon and Barsi, Christopher and Willwacher, Thomas and Dai, Qionghai and Raskar, Ramesh",
        "doi": "10.1007/s11263-013-0686-0",
        "issn": "15731405",
        "journal": "International Journal of Computer Vision",
        "keywords": "Computational photography,Frequency analysis,Lensless imaging,Light transport",
        "month": "nov",
        "number": "2",
        "pages": "128--140",
        "publisher": "Kluwer Academic Publishers",
        "title": "{Ultra-fast Lensless Computational Imaging through 5D Frequency Analysis of Time-resolved Light Transport}",
        "type": "article",
        "url": "https://link.springer.com/article/10.1007/s11263-013-0686-0 http://link.springer.com/10.1007/s11263-013-0686-0",
        "volume": "110",
        "year": "2014"
    },
    "Wu2017": {
        "abstract": "{\\textcopyright} 2017 Optical Society of America. The need to image objects through light-scattering materials is common in a range of applications. Different methods have been investigated to acquire the image of the object when diffusers are presented. In this paper, we demonstrate the object reconstruction with single-shot imaging based on the correlography principle and phase retrieval algorithm with coherent illumination. We prove the possibility of reconstructing positive and negative objects in both transmission and reflection modes with collimated and scattered light. Formulas for calculating the size of the object from the reconstructed image are presented. We also prove that the object can be retrieved from a small section of the raw speckle image. These interesting features will have broad potential applications in many areas (such as biomedicine, security and sensing).",
        "author": "Wu, Pengfei and Liang, Zi and Zhao, Xing and Su, Lei and Song, Lipei",
        "doi": "10.1364/AO.56.003335",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Wu et al. - 2017 - Lensless wide-field single-shot imaging through turbid media based on object-modulated speckles.pdf:pdf",
        "issn": "0003-6935",
        "journal": "Applied Optics",
        "keywords": "(1100113) Imaging through turbid media,(1206150) Speckle imaging,OCIS codes: (1100110) Imaging systems",
        "month": "apr",
        "number": "12",
        "pages": "3335",
        "pmid": "28430254",
        "publisher": "The Optical Society",
        "title": "{Lensless wide-field single-shot imaging through turbid media based on object-modulated speckles}",
        "type": "article",
        "url": "https://doi.org/10.1364/AO.56.003335 https://www.osapublishing.org/abstract.cfm?URI",
        "volume": "56",
        "year": "2017"
    },
    "Wu2018": {
        "abstract": "Optical compound microscope has been a major tool in biomedical imaging for centuries. Its performance relies on relatively complicated, bulky and expensive lenses and alignment mechanics. In contrast, the lensless microscope digitally reconstructs microscopic images of specimens without using any lenses, as a result of which it can be made much smaller, lighter and lower-cost. Furthermore, the limited space-bandwidth product of objective lenses in a conventional microscope can be significantly surpassed by a lensless microscope. Such lensless imaging designs have enabled high-resolution and high-throughput imaging of specimens using compact, portable and cost-effective devices to potentially address various point-of-care, global-health and telemedicine related challenges. In this review, we discuss the operation principles and the methods behind lensless digital holographic on-chip microscopy. We also go over various applications that are enabled by cost-effective and compact implementations of lensless microscopy, including some recent work on air quality monitoring, which utilized machine learning for high-throughput and accurate quantification of particulate matter in air. Finally, we conclude with a brief future outlook of this computational imaging technology.",
        "author": "Wu, Yichen and Ozcan, Aydogan",
        "booktitle": "Methods",
        "doi": "10.1016/j.ymeth.2017.08.013",
        "issn": "10959130",
        "keywords": "Application:Microscopy,Mask:Holography,Type:Lensless",
        "month": "mar",
        "pages": "4--16",
        "pmid": "28864356",
        "publisher": "Academic Press Inc.",
        "title": "{Lensless digital holographic microscopy and its applications in biomedicine and environmental monitoring}",
        "type": "misc",
        "volume": "136",
        "year": "2018"
    },
    "Wu2019": {
        "abstract": "Wavefront sensing is the simultaneous measurement of the amplitude and phase of an incoming optical field. Traditional wavefront sensors such as Shack-Hartmann wavefront sensor (SHWFS) suffer from a fundamental tradeoff between spatial resolution and phase estimation and consequently can only achieve a resolution of a few thousand pixels. To break this tradeoff, we present a novel computational-imaging-based technique, namely, the Wavefront Imaging Sensor with High resolution (WISH). We replace the microlens array in SHWFS with a spatial light modulator (SLM) and use a computational phase-retrieval algorithm to recover the incident wavefront. This wavefront sensor can measure highly varying optical fields at more than 10-megapixel resolution with the fine phase estimation. To the best of our knowledge, this resolution is an order of magnitude higher than the current noninterferometric wavefront sensors. To demonstrate the capability of WISH, we present three applications, which cover a wide range of spatial scales. First, we produce the diffraction-limited reconstruction for long-distance imaging by combining WISH with a large-aperture, low-quality Fresnel lens. Second, we show the recovery of high-resolution images of objects that are obscured by scattering. Third, we show that WISH can be used as a microscope without an objective lens. Our study suggests that the designing principle of WISH, which combines optical modulators and computational algorithms to sense high-resolution optical fields, enables improved capabilities in many existing applications while revealing entirely new, hitherto unexplored application areas.",
        "author": "Wu, Yicheng and Sharma, Manoj Kumar and Veeraraghavan, Ashok",
        "doi": "10.1038/s41377-019-0154-x",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Wu, Sharma, Veeraraghavan - 2019 - WISH wavefront imaging sensor with high resolution.pdf:pdf",
        "issn": "20477538",
        "journal": "Light: Science and Applications",
        "keywords": "Application:Wavefront,Mask:SLM",
        "month": "dec",
        "number": "1",
        "pages": "2047--7538",
        "publisher": "Nature Publishing Group",
        "title": "{WISH: wavefront imaging sensor with high resolution}",
        "type": "article",
        "url": "www.nature.com/lsa",
        "volume": "8",
        "year": "2019"
    },
    "Wu2019a": {
        "abstract": "Deep learning brings bright-field microscopy contrast to holographic images of a sample volume, bridging the volumetric imaging capability of holography with the speckle-And artifact-free image contrast of bright-field incoherent microscopy. MSC Codes 68T01, 68T05, 68U10, 62M45, 78M32, 92C55, 94A08",
        "archiveprefix": "arXiv",
        "arxivid": "1811.07103",
        "author": "Wu, Yichen and Luo, Yilin and Chaudhari, Gunvant and Rivenson, Yair and Calis, Ayfer and de Haan, Kevin and Ozcan, Aydogan",
        "doi": "10.1038/s41377-019-0139-9",
        "eprint": "1811.07103",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Wu et al. - 2019 - Bright-field holography cross-modality deep learning enables snapshot 3D imaging with bright-field contrast using a s.pdf:pdf",
        "issn": "2047-7538",
        "journal": "Light: Science & Applications",
        "keywords": "Application:Microscopy,Mask:Holography,Type:Lensless",
        "month": "dec",
        "number": "1",
        "pages": "25",
        "publisher": "arXiv",
        "title": "{Bright-field holography: cross-modality deep learning enables snapshot 3D imaging with bright-field contrast using a single hologram}",
        "type": "article",
        "url": "http://creativecommons.org/licenses/by/4.0/.Correspondence:AydoganOzcan http://www.nature.com/articles/s41377-019-0139-9",
        "volume": "8",
        "year": "2019"
    },
    "Wu2020": {
        "abstract": "Lensless imaging eliminates the need for geometric isomorphism between a scene and an image while allowing the construction of compact, lightweight imaging systems. However, a challenging inverse problem remains due to the low reconstructed signal-to-noise ratio. Current implementations require multiple masks or multiple shots to denoise the reconstruction. We propose single-shot lensless imaging with a Fresnel zone aperture and incoherent illumination. By using the Fresnel zone aperture to encode the incoherent rays in wavefront-like form, the captured pattern has the same form as the inline hologram. Since conventional backpropagation reconstruction is troubled by the twin-image problem, we show that the compressive sensing algorithm is effective in removing this twin-image artifact due to the sparsity in natural scenes. The reconstruction with a significantly improved signal-to-noise ratio from a single-shot image promotes a camera architecture that is flat and reliable in its structure and free of the need for strict calibration.",
        "author": "Wu, Jiachen and Zhang, Hua and Zhang, Wenhui and Jin, Guofan and Cao, Liangcai and Barbastathis, George",
        "doi": "10.1038/s41377-020-0289-9",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Wu et al. - Unknown - Single-shot lensless imaging with fresnel zone aperture and incoherent illumination.pdf:pdf",
        "isbn": "4137702002899",
        "issn": "20477538",
        "journal": "Light: Science and Applications",
        "keywords": "Mask:Amplitude mask,PSF:FZA",
        "number": "1",
        "pages": "2047--7538",
        "title": "{Single-shot lensless imaging with fresnel zone aperture and incoherent illumination}",
        "type": "article",
        "url": "www.nature.com/lsa",
        "volume": "9",
        "year": "2020"
    },
    "Wu2021": {
        "abstract": "In mask-based lensless imaging, iterative reconstruction methods based on the geometric optics model produce artifacts and are computationally expensive. We present a prototype of a lensless camera that uses a deep neural network (DNN) to realize rapid reconstruction for Fresnel zone aperture (FZA) imaging. A deep back-projection network (DBPN) is connected behind a U-Net providing an error feedback mechanism, which realizes the self-correction of features to recover the image detail. A diffraction model generates the training data under conditions of broadband incoherent imaging. In the reconstructed results, blur caused by diffraction is shown to have been ameliorated, while the computing time is 2 orders of magnitude faster than the traditional iterative image reconstruction algorithms. This strategy could drastically reduce the design and assembly costs of cameras, paving the way for integration of portable sensors and systems.",
        "author": "Wu, Jiachen and Cao, Liangcai and Barbastathis, George",
        "doi": "10.1364/ol.411228",
        "issn": "0146-9592",
        "journal": "Optics Letters",
        "keywords": "Algorithm:DNN,Mask:Amplitude mask,PSF:FZA",
        "month": "jan",
        "number": "1",
        "pages": "130",
        "pmid": "33362033",
        "publisher": "The Optical Society",
        "title": "{DNN-FZA camera: a deep learning approach toward broadband FZA lensless imaging}",
        "type": "article",
        "url": "https://www.osapublishing.org/viewmedia.cfm?uri",
        "volume": "46",
        "year": "2021"
    },
    "Yang2018": {
        "abstract": "We report a resolution-enhanced lensless color shadow imaging microscopy (RELCSIM) system based on large field-of-view (FOV) submicron-pixel imaging sensors. The physical pixel size of our custom made imaging chip is 0.95um \u00d7 0.95um, and the pixel-count is 25 millions (5120H \u00d7 5120V). By directly recording the shadow of the samples without any postprocssing, we have realized a microscope with a half-pitch resolution of $\\sim$ 1um and a FOV of $\\sim$ 25mm2 simutaneously. To verify the resolution of our system, the grating samples coated on the surface of the chip are imaged. We further demonstrate the monochromatic and color shadow imaging of muscle tissue specimens with the prototype, which show the potential for applications such as diagnostic pathology.",
        "author": "Yang, Cheng and Bu, Xiaofeng and Ma, Haowen and Zhang, Limin and Cao, Xu and Yue, Tao and Hua, Xia and Yan, Feng",
        "booktitle": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops",
        "doi": "10.1109/CVPRW.2018.00301",
        "isbn": "9781538661000",
        "issn": "21607516",
        "keywords": "Mask:Shadow,Type:Lensless",
        "month": "dec",
        "pages": "2327--2334",
        "publisher": "IEEE Computer Society",
        "title": "{Resolution-enhanced lensless color shadow imaging microscopy based on large field-of-view submicron-pixel imaging sensors}",
        "type": "inproceedings",
        "volume": "2018-June",
        "year": "2018"
    },
    "Yuan2018": {
        "abstract": "We report a parallel lensless compressive imaging system, which enjoys real-time reconstruction using deep convolutional neural networks. A prototype composed of a low-cost LCD, 16 photo-diodes and isolation chambers, has been built. Each of these 16 channels captures a fraction of the scene with 16&#x000D7;16 pixels and they are performing in parallel. An efficient inversion algorithm based on deep convolutional neural networks is developed to reconstruct the image. We have demonstrated encouraging results using only 2&#x00025; (relative to pixel numbers, e.g. 5 for a block with 16&#x000D7;16 pixels) measurements per sensor for digits and around 10&#x00025; measurements per sensor for facial images.",
        "author": "Yuan, Xin and Pu, Yunchen",
        "doi": "10.1364/oe.26.001962",
        "issn": "1094-4087",
        "journal": "Optics Express",
        "keywords": "(1000100) Image processing,(1101758) Computational imaging,OCIS codes: (1100110) Imaging systems,Type:Lensless",
        "month": "jan",
        "number": "2",
        "pages": "1962",
        "pmid": "29401917",
        "publisher": "The Optical Society",
        "title": "{Parallel lensless compressive imaging via deep convolutional neural networks}",
        "type": "article",
        "url": "https://doi.org/10.1364/OE.26.001962",
        "volume": "26",
        "year": "2018"
    },
    "Zheng2010": {
        "abstract": "We report the implementation of a fully on-chip, lensless, sub-pixel resolving optofluidic microscope (SROFM). The device utilizes microfluidic flow to deliver specimens directly across a complementary metal oxide semiconductor (CMOS) sensor to generate a sequence of low-resolution (LR) projection images, where resolution is limited by the sensor's pixel size. This image sequence is then processed with a pixel super-resolution algorithm to reconstruct a single high resolution (HR) image, where features beyond the Nyquist rate of the LR images are resolved. We demonstrate the device's capabilities by imaging microspheres, protist Euglena gracilis, and Entamoeba invadens cysts with sub-cellular resolution and establish that our prototype has a resolution limit of 0.75 microns. Furthermore, we also apply the same pixel super-resolution algorithm to reconstruct HR videos in which the dynamic interaction between the fluid and the sample, including the in-plane and out-of-plane rotation of the sample within the flow, can be monitored in high resolution. We believe that the powerful combination of both the pixel super-resolution and optofluidic microscopy techniques within our SROFM is a significant step forwards toward a simple, cost-effective, high throughput and highly compact imaging solution for biomedical and bioscience needs. {\\textcopyright} 2010 The Royal Society of Chemistry.",
        "author": "Zheng, Guoan and Lee, Seung Ah and Yang, Samuel and Yang, Changhuei",
        "doi": "10.1039/c0lc00213e",
        "file": ":Users/vivekboominathan/Library/Application Support/Mendeley Desktop/Downloaded/Zheng et al. - 2010 - Sub-pixel resolving optofluidic microscope for on-chip cell imaging.pdf:pdf",
        "issn": "14730189",
        "journal": "Lab on a Chip",
        "keywords": "Mask:Shadow,Type,Type:Lensless",
        "mendeley-tags": "Mask:Shadow",
        "month": "nov",
        "number": "22",
        "pages": "3125--3129",
        "publisher": "Royal Society of Chemistry",
        "title": "{Sub-pixel resolving optofluidic microscope for on-chip cell imaging}",
        "type": "article",
        "url": "https://pubmed.ncbi.nlm.nih.gov/20877904/",
        "volume": "10",
        "year": "2010"
    },
    "Zhou2018": {
        "abstract": "Lensless imaging is a technique that records diffraction patterns without using lenses and recovers the complex field of object via phase retrieval. Robust lensless phase retrieval process usually requires multiple measurements with defocus variation, transverse translation or angle-varied illumination. However, making such diverse measurements is time-consuming and limits the application of lensless setup for dynamic samples. In this paper, we propose a single-shot lensless imaging scheme via simultaneous multi-angle LED illumination. Diffraction patterns under multi-angle lights are recorded by different areas of the sensor within a single shot. An optimization algorithm is applied to utilize the single-shot measurement and retrieve the aliasing information for reconstruction. We first use numerical simulations to evaluate the proposed scheme quantitatively by comparisons with the multi-acquisition case. Then a proof-of-concept lensless setup is built to validate the method by imaging a resolution chart and biological samples, achieving &#x0223C; 4.92 &#x003BC;m half-pitch resolution and &#x0223C; 1.202mm2 field of view (FOV). We also discuss different design tradeoffs and present a 4-frame acquisition scheme (with &#x0223C; 3.48 &#x003BC;m half-pitch resolution and &#x0223C; 2.35 &#x000D7; 2.55 mm2 FOV) to show the flexibility of performance enhancement by capturing more measurements.",
        "author": "Zhou, You and Wu, Jiamin and Suo, Jinli and Han, Xiaofei and Zheng, Guoan and Dai, Qionghai",
        "doi": "10.1364/oe.26.021418",
        "issn": "1094-4087",
        "journal": "Optics Express",
        "keywords": "Mask:Holography,Mask:Multi-angle",
        "month": "aug",
        "number": "17",
        "pages": "21418",
        "pmid": "30130850",
        "publisher": "The Optical Society",
        "title": "{Single-shot lensless imaging via simultaneous multi-angle LED illumination}",
        "type": "article",
        "url": "https://doi.org/10.1364/OE.26.021418",
        "volume": "26",
        "year": "2018"
    },
    "Zomet2006": {
        "abstract": "In this paper we propose a novel, highly flexible camera. The camera consists of an image detector and a special aperture, but no lens. The aperture is a set of parallel light attenuating layers whose transmittances are controllable in space and time. By applying different transmittance patterns to this aperture, it is possible to modulate the incoming light in useful ways and capture images that are impossible to capture with conventional lens-based cameras. For example, the camera can pan and tilt its field of view without the use of any moving parts. It can also capture disjoint regions of interest in the scene without having to capture the regions in between them. In addition, the camera can be used as a computational sensor, where the detector measures the end result of computations performed by the attenuating layers on the scene radiance values. These and other imaging functionalities can be implemented with the same physical camera and the functionalities can be switched from one video frame to the next via software. We have built a prototype camera based on this approach using a bare image detector and a liquid crystal modulator for the aperture. We discuss in detail the merits and limitations of lensless imaging using controllable apertures. {\\textcopyright} 2006 IEEE.",
        "author": "Zomet, Assaf and Nayar, Shree K.",
        "booktitle": "Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",
        "doi": "10.1109/CVPR.2006.175",
        "isbn": "0769525970",
        "issn": "10636919",
        "keywords": "Mask:Amplitude mask,Mask:LCD,Mask:Programmable",
        "pages": "339--346",
        "title": "{Lensless imaging with a controllable aperture}",
        "type": "inproceedings",
        "volume": "1",
        "year": "2006"
    },
    "stork2014optical": {
        "author": "Stork, David G. and Gill, Patrick R.",
        "journal": "International Journal on Advances in Systems and Measurements",
        "keywords": "Mask:Phase gratings",
        "number": "3",
        "pages": "4",
        "publisher": "Citeseer",
        "title": "{Optical, mathematical, and computational foundations of lensless ultra-miniature diffractive imagers and sensors}",
        "type": "article",
        "volume": "7",
        "year": "2014"
    }
}});